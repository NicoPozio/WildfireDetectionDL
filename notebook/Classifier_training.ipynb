{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoPozio/WildfireDetectionDL/blob/main/notebook/Classifier_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NicoPozio/WildfireDetectionDL.git"
      ],
      "metadata": {
        "id": "NUhUF7tDYgzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617e4dd9-7396-4c7d-b3bd-543d9ae7579f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WildfireDetectionDL'...\n",
            "remote: Enumerating objects: 275, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 275 (delta 43), reused 2 (delta 0), pack-reused 188 (from 1)\u001b[K\n",
            "Receiving objects: 100% (275/275), 287.44 KiB | 8.71 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "repo_path = '/content/WildfireDetectionDL'\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "F1sXhKEnf1dO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Update Code\n",
        "import os\n",
        "\n",
        "REPO_PATH = \"/content/WildfireDetectionDL\"\n",
        "\n",
        "print(\"Syncing with GitHub...\")\n",
        "!cd {REPO_PATH} && git pull\n",
        "\n",
        "print(\"Code updated. You can now run the Sweep or Train cell immediately.\")"
      ],
      "metadata": {
        "id": "hpvQdBgJvSDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db05e6ee-8553-4305-e3da-eb4f2db3266e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syncing with GitHub...\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 1.45 KiB | 1.45 MiB/s, done.\n",
            "From https://github.com/NicoPozio/WildfireDetectionDL\n",
            "   c4ca0fb..ad8e4b9  main       -> origin/main\n",
            "Updating c4ca0fb..ad8e4b9\n",
            "Fast-forward\n",
            " test.py | 48 \u001b[32m++++++++++++++++++\u001b[m\u001b[31m------------------------------\u001b[m\n",
            " 1 file changed, 18 insertions(+), 30 deletions(-)\n",
            "Code updated. You can now run the Sweep or Train cell immediately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Project Dependencies\n",
        "#hydra-core: Configuration management\n",
        "#wandb: Experiment tracking\n",
        "#omegaconf: Dict handling for Hydra\n",
        "!pip install -q hydra-core wandb omegaconf\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive Mounted\")\n"
      ],
      "metadata": {
        "id": "xYMO3qvxQo_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae38a220-1813-48d4-8e13-a0b313c9ce35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Google Drive Mounted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    #Fetch key from Colab Secrets\n",
        "    api_key = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    #Set as Environment Variable\n",
        "    #This ensures Hydra and subprocesses can find it automatically\n",
        "    os.environ[\"WANDB_API_KEY\"] = api_key\n",
        "\n",
        "    wandb.login()\n",
        "    print(\"Logged in to WandB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication Failed: {e}\")\n",
        "    print(\"Action Required: Go to the 'Secrets' tab (Key icon) on the left.\")\n",
        "    print(\"Add a new secret named 'WANDB_API_KEY' with your key from https://wandb.ai/authorize\")"
      ],
      "metadata": {
        "id": "HRabcBKtQqgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3317e534-d008-491a-e944-ca6658a6ff9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in to WandB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we download the dataset, we check if the user has the data in its google drive, if not it's downloaded from a public link"
      ],
      "metadata": {
        "id": "Ti3-Olu9Xnqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "509SQeSJXm1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def0f09e-42f1-4231-d257-0dc470da7732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42860/42860 [00:12<00:00, 3408.37files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Extracting synthetic_wildfire_2k.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2003/2003 [00:01<00:00, 1328.80files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Data Ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "from src.utils import extract_zip\n",
        "\n",
        "#Destination on Colab\n",
        "local_root = \"/content/data\"\n",
        "os.makedirs(local_root, exist_ok=True)\n",
        "!rm -rf {local_root}/*\n",
        "\n",
        "#Paths on drive (in case the CyclaGAN notebook is exectued)\n",
        "drive_dataset_path = \"/content/drive/MyDrive/Wildfire_Project/dataset.zip\"\n",
        "drive_synthetic_path = \"/content/drive/MyDrive/Wildfire_Project/synthetic_wildfire_2k.zip\"\n",
        "\n",
        "#Paths on Colab\n",
        "target_dataset_zip = os.path.join(local_root, \"dataset.zip\")\n",
        "target_synthetic_zip = os.path.join(local_root, \"synthetic_wildfire_2k.zip\")\n",
        "\n",
        "\n",
        "\n",
        "#Check if the file are present\n",
        "if os.path.isfile(drive_dataset_path) and os.path.isfile(drive_synthetic_path):\n",
        "    !cp \"{drive_dataset_path}\" \"{target_dataset_zip}\"\n",
        "    !cp \"{drive_synthetic_path}\" \"{target_synthetic_zip}\"\n",
        "\n",
        "else:\n",
        "\n",
        "    DATASET_ID = \"17KPBVodZkmBYqz7252mDk6hfY55eMU-Q\"\n",
        "    SYNTHETIC_ID = \"1KyI09FDCAkLp1BYO-VgD7zRMrtrl3anK\"\n",
        "\n",
        "    gdown.download(id=DATASET_ID, output=target_dataset_zip, quiet=False)\n",
        "\n",
        "    gdown.download(id=SYNTHETIC_ID, output=target_synthetic_zip, quiet=False)\n",
        "\n",
        "\n",
        "if os.path.exists(target_dataset_zip) and os.path.exists(target_synthetic_zip):\n",
        "    if os.path.getsize(target_dataset_zip) > 0:\n",
        "        extract_zip(target_dataset_zip, local_root)\n",
        "    if os.path.getsize(target_synthetic_zip) > 0:\n",
        "        extract_zip(target_synthetic_zip, local_root)\n",
        "    print(\"Data Ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define your data root\n",
        "DATA_ROOT = \"/content/data\"\n",
        "\n",
        "print(f\"Scanning {DATA_ROOT} for corrupt images...\")\n",
        "\n",
        "corrupt_count = 0\n",
        "for root, dirs, files in os.walk(DATA_ROOT):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            file_path = os.path.join(root, filename)\n",
        "            try:\n",
        "                # Try to fully load the image bytes\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()\n",
        "            except OSError:\n",
        "                print(f\"Found corrupt image: {file_path}\")\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                    print(f\"Deleted {filename}\")\n",
        "                    corrupt_count += 1\n",
        "                except:\n",
        "                    print(f\"Could not delete {filename}\")\n",
        "\n",
        "print(f\"\\nScan Complete. Removed {corrupt_count} corrupt files.\")"
      ],
      "metadata": {
        "id": "pNVIFW9gqYb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2a2b83-5b4d-4b7d-819f-8cff9609e486"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning /content/data for corrupt images...\n",
            "Found corrupt image: /content/data/dataset/test/wildfire/-73.15884,46.38819.jpg\n",
            "Deleted -73.15884,46.38819.jpg\n",
            "Found corrupt image: /content/data/dataset/train/nowildfire/-114.152378,51.027198.jpg\n",
            "Deleted -114.152378,51.027198.jpg\n",
            "\n",
            "Scan Complete. Removed 2 corrupt files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# 1. Define Paths Constants\n",
        "REPO_ROOT = \"/content/WildfireDetectionDL\"\n",
        "SWEEP_CONFIG_PATH = os.path.join(REPO_ROOT, \"conf\", \"sweep.yaml\")\n",
        "\n",
        "# 2. Validation\n",
        "if not os.path.exists(SWEEP_CONFIG_PATH):\n",
        "    print(f\"CRITICAL ERROR: Could not find sweep.yaml at {SWEEP_CONFIG_PATH}\")\n",
        "else:\n",
        "    print(f\"Registering Sweep from {SWEEP_CONFIG_PATH}\")\n",
        "\n",
        "    # 3. Register the sweep\n",
        "    result = subprocess.run(\n",
        "        [\"wandb\", \"sweep\", SWEEP_CONFIG_PATH],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        # CORRECTION: cwd must be the directory, not the file\n",
        "        cwd=REPO_ROOT\n",
        "    )\n",
        "\n",
        "    output_text = result.stderr + result.stdout\n",
        "    print(\"Raw Output:\", output_text)\n",
        "\n",
        "    # 4. Extract Sweep ID\n",
        "    sweep_id = None\n",
        "    for line in output_text.split('\\n'):\n",
        "        if \"wandb agent\" in line:\n",
        "            parts = line.strip().split(\"wandb agent \")\n",
        "            if len(parts) > 1:\n",
        "                sweep_id = parts[-1].strip()\n",
        "                break\n",
        "\n",
        "    # 5. Launch the Agent\n",
        "    if sweep_id:\n",
        "        print(f\"\\nSUCCESS: Detected Sweep ID: {sweep_id}\")\n",
        "        print(\"Starting Agent... (This will run multiple experiments)\")\n",
        "\n",
        "        # CORRECTION: We use the explicit REPO_ROOT variable defined at the top\n",
        "        !cd {REPO_ROOT} && wandb agent {sweep_id} --count 20\n",
        "    else:\n",
        "        print(\"\\nERROR: Could not find Sweep ID.\")"
      ],
      "metadata": {
        "id": "OE8v94eqa7zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0034c387-2513-46f8-ce33-59c101e3e97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering Sweep from /content/WildfireDetectionDL/conf/sweep.yaml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-881789450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 3. Register the sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     result = subprocess.run(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"wandb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSWEEP_CONFIG_PATH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the sweep execution we found the best configuration for the neural networks, now we train the resnet50 using that parameters, we train using both synthetic+real, and only real"
      ],
      "metadata": {
        "id": "qLOavfqgtSmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "# 1. ResNet50\n",
        "RESNET_CONFIG = [\n",
        "    \"model.name=resnet50\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=11\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00005836874490583941\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000621085260935666\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "# 2. SimpleCNN\n",
        "SIMPLE_CNN_CONFIG = [\n",
        "    \"model.name=simple_cnn\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=4\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00001349\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000823\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "# 3. EfficientNet\n",
        "EFFICIENTNET_CONFIG = [\n",
        "    \"model.name=efficientnet\",\n",
        "    \"model.dropout=0.2\",\n",
        "    \"dataset.augmentation.rotation_degrees=15\",\n",
        "    \"training.batch_size=32\",\n",
        "    \"training.learning_rate=0.0001\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.0\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Hyperparameter Configurations\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. ResNet50 (Transfer Learning)\n",
        "RESNET_CONFIG = [\n",
        "    \"model.name=resnet50\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=11\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00011485\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00009848\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "# 2. SimpleCNN (Custom Architecture)\n",
        "SIMPLE_CNN_CONFIG = [\n",
        "    \"model.name=simple_cnn\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=4\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00001349\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000823\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "# 3. EfficientNet (Modern Architecture)\n",
        "EFFICIENTNET_CONFIG = [\n",
        "    \"model.name=efficientnet\",\n",
        "    \"model.dropout=0.2\",\n",
        "    \"dataset.augmentation.rotation_degrees=15\",\n",
        "    \"training.batch_size=32\",\n",
        "    \"training.learning_rate=0.0001\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.0\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.5\"\n",
        "]\n",
        "\n",
        "# Pipeline Logic (Fixed for Real-Time Output)\n",
        "\n",
        "def run_training_pipeline(model_label, use_synthetic, config_list):\n",
        "    run_id = f\"{model_label}_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STARTING TRAINING PIPELINE: {run_id}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Construct Training Command\n",
        "    train_cmd = [\n",
        "        sys.executable, \"train.py\",\n",
        "        f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "        \"wandb.project=wildfire-final-benchmark\",\n",
        "        f\"+wandb.name={run_id}\"\n",
        "    ] + config_list\n",
        "\n",
        "    # Execute with Popen to stream output line-by-line\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            train_cmd,\n",
        "            cwd=\"/content/WildfireDetectionDL\",\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT, # Merge errors into standard output\n",
        "            text=True,\n",
        "            bufsize=1, # Line buffered\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Print output as it happens\n",
        "        for line in process.stdout:\n",
        "            print(line, end=\"\")\n",
        "\n",
        "        process.wait()\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"\\nTRAINING FAILED: {run_id}\")\n",
        "            return False\n",
        "        else:\n",
        "            print(\"\\nTraining Complete.\")\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL ERROR: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# ResNet50\n",
        "run_training_pipeline(\"ResNet50\", False, RESNET_CONFIG)\n",
        "run_training_pipeline(\"ResNet50\", True, RESNET_CONFIG)\n",
        "\n",
        "# SimpleCNN\n",
        "run_training_pipeline(\"SimpleCNN\", False, SIMPLE_CNN_CONFIG)\n",
        "run_training_pipeline(\"SimpleCNN\", True, SIMPLE_CNN_CONFIG)\n",
        "\n",
        "# EfficientNet\n",
        "run_training_pipeline(\"EfficientNet\", False, EFFICIENTNET_CONFIG)\n",
        "run_training_pipeline(\"EfficientNet\", True, EFFICIENTNET_CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_3baXIXtQ20",
        "outputId": "7bfa35f5-3d6b-4e20-b712-67bd10688ace"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: ResNet50_RealOnly\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run strm81l9\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_090048-strm81l9\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run super-music-22\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/strm81l9\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: resnet50\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 237\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 1:   9%|‚ñâ         | 21/237 [00:10<01:45,  2.05it/s]\n",
            "Epoch 1:  23%|‚ñà‚ñà‚ñé       | 54/237 [00:20<01:06,  2.76it/s]\n",
            "Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 87/237 [00:30<00:50,  2.99it/s]\n",
            "Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 120/237 [00:40<00:37,  3.09it/s]\n",
            "Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 153/237 [00:50<00:26,  3.15it/s]\n",
            "Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 186/237 [01:00<00:16,  3.18it/s]\n",
            "Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 219/237 [01:11<00:05,  3.20it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:17<00:00,  3.05it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.37%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 2:  14%|‚ñà‚ñé        | 32/237 [00:10<01:05,  3.11it/s]\n",
            "Epoch 2:  27%|‚ñà‚ñà‚ñã       | 65/237 [00:20<00:54,  3.18it/s]\n",
            "Epoch 2:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 98/237 [00:30<00:43,  3.20it/s]\n",
            "Epoch 2:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 131/237 [00:40<00:33,  3.21it/s]\n",
            "Epoch 2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 164/237 [00:51<00:22,  3.22it/s]\n",
            "Epoch 2:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 197/237 [01:01<00:12,  3.22it/s]\n",
            "Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 230/237 [01:11<00:02,  3.22it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:13<00:00,  3.22it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.35%\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 3:  13%|‚ñà‚ñé        | 31/237 [00:10<01:06,  3.09it/s]\n",
            "Epoch 3:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.16it/s]\n",
            "Epoch 3:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:43,  3.18it/s]\n",
            "Epoch 3:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/237 [00:40<00:33,  3.19it/s]\n",
            "Epoch 3:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 163/237 [00:51<00:23,  3.20it/s]\n",
            "Epoch 3:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 196/237 [01:01<00:12,  3.20it/s]\n",
            "Epoch 3:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 229/237 [01:11<00:02,  3.20it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.20it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.94%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 4:  13%|‚ñà‚ñé        | 31/237 [00:10<01:06,  3.08it/s]\n",
            "Epoch 4:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 4:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 4:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:40<00:33,  3.18it/s]\n",
            "Epoch 4:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 161/237 [00:50<00:23,  3.19it/s]\n",
            "Epoch 4:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 193/237 [01:00<00:13,  3.19it/s]\n",
            "Epoch 4:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/237 [01:10<00:03,  3.19it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.00%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 5:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 5:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:20<00:55,  3.15it/s]\n",
            "Epoch 5:  40%|‚ñà‚ñà‚ñà‚ñà      | 95/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 5:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 5:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/237 [00:50<00:24,  3.18it/s]\n",
            "Epoch 5:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 191/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 5:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 223/237 [01:10<00:04,  3.19it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.83%\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 6:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 6:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:20<00:55,  3.14it/s]\n",
            "Epoch 6:  40%|‚ñà‚ñà‚ñà‚ñà      | 95/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 6:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 6:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/237 [00:50<00:24,  3.19it/s]\n",
            "Epoch 6:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 191/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 6:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 223/237 [01:10<00:04,  3.19it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.94%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 7:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 7:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:20<00:55,  3.15it/s]\n",
            "Epoch 7:  40%|‚ñà‚ñà‚ñà‚ñà      | 95/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 7:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 7:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/237 [00:50<00:24,  3.19it/s]\n",
            "Epoch 7:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 191/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 7:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 223/237 [01:10<00:04,  3.19it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.11%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 8:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 8:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 8:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 8:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:40<00:33,  3.18it/s]\n",
            "Epoch 8:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 161/237 [00:50<00:23,  3.19it/s]\n",
            "Epoch 8:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 193/237 [01:00<00:13,  3.19it/s]\n",
            "Epoch 8:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 226/237 [01:11<00:03,  3.19it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.95%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 9:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 9:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 9:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 9:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/237 [00:41<00:33,  3.18it/s]\n",
            "Epoch 9:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 162/237 [00:51<00:23,  3.19it/s]\n",
            "Epoch 9:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 194/237 [01:01<00:13,  3.19it/s]\n",
            "Epoch 9:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 226/237 [01:11<00:03,  3.19it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.08%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 10:  13%|‚ñà‚ñé        | 31/237 [00:10<01:06,  3.08it/s]\n",
            "Epoch 10:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 10:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 10:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:40<00:33,  3.18it/s]\n",
            "Epoch 10:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 161/237 [00:50<00:23,  3.19it/s]\n",
            "Epoch 10:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 193/237 [01:00<00:13,  3.19it/s]\n",
            "Epoch 10:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/237 [01:10<00:03,  3.19it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.13%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 11:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 11:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:20<00:55,  3.15it/s]\n",
            "Epoch 11:  40%|‚ñà‚ñà‚ñà‚ñà      | 95/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 11:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 11:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/237 [00:50<00:24,  3.19it/s]\n",
            "Epoch 11:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 191/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 11:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 224/237 [01:10<00:04,  3.19it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.10%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 12:  13%|‚ñà‚ñé        | 31/237 [00:10<01:06,  3.08it/s]\n",
            "Epoch 12:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 12:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 12:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:40<00:33,  3.18it/s]\n",
            "Epoch 12:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 161/237 [00:50<00:23,  3.19it/s]\n",
            "Epoch 12:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 193/237 [01:00<00:13,  3.19it/s]\n",
            "Epoch 12:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/237 [01:10<00:03,  3.19it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.52%\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 13:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 13:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:20<00:55,  3.14it/s]\n",
            "Epoch 13:  40%|‚ñà‚ñà‚ñà‚ñà      | 95/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 13:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 127/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 13:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 159/237 [00:50<00:24,  3.18it/s]\n",
            "Epoch 13:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 191/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 13:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 223/237 [01:10<00:04,  3.19it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.76%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 14:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 14:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 14:  41%|‚ñà‚ñà‚ñà‚ñà      | 96/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 14:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 128/237 [00:40<00:34,  3.18it/s]\n",
            "Epoch 14:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 160/237 [00:50<00:24,  3.19it/s]\n",
            "Epoch 14:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 192/237 [01:00<00:14,  3.19it/s]\n",
            "Epoch 14:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/237 [01:10<00:03,  3.19it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.54%\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 15:  13%|‚ñà‚ñé        | 31/237 [00:10<01:07,  3.07it/s]\n",
            "Epoch 15:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:54,  3.15it/s]\n",
            "Epoch 15:  41%|‚ñà‚ñà‚ñà‚ñà      | 97/237 [00:30<00:44,  3.17it/s]\n",
            "Epoch 15:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:40<00:33,  3.18it/s]\n",
            "Epoch 15:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 161/237 [00:50<00:23,  3.19it/s]\n",
            "Epoch 15:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 193/237 [01:00<00:13,  3.19it/s]\n",
            "Epoch 15:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 225/237 [01:10<00:03,  3.19it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [01:14<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading history steps 14-14, summary, console lines 90-92\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÅ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÉ‚ñÖ‚ñÉ‚ñÇ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 15\n",
            "wandb: val_acc 98.44444\n",
            "wandb: \n",
            "wandb: üöÄ View run super-music-22 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/strm81l9\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_090048-strm81l9/logs\n",
            "   Val Acc: 98.44%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: ResNet50_Synthetic\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run yjfbolr4\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_092315-yjfbolr4\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run royal-gorge-23\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/yjfbolr4\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: resnet50\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 17124 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 268\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 1:   7%|‚ñã         | 20/268 [00:10<02:05,  1.98it/s]\n",
            "Epoch 1:  20%|‚ñà‚ñâ        | 53/268 [00:20<01:19,  2.71it/s]\n",
            "Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 86/268 [00:30<01:01,  2.94it/s]\n",
            "Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 119/268 [00:40<00:48,  3.04it/s]\n",
            "Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 152/268 [00:51<00:37,  3.10it/s]\n",
            "Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 185/268 [01:01<00:26,  3.14it/s]\n",
            "Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 218/268 [01:11<00:15,  3.16it/s]\n",
            "Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 251/268 [01:22<00:05,  3.18it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:29<00:00,  3.01it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.90%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 2:  12%|‚ñà‚ñè        | 31/268 [00:10<01:16,  3.08it/s]\n",
            "Epoch 2:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.16it/s]\n",
            "Epoch 2:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.18it/s]\n",
            "Epoch 2:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:40<00:43,  3.19it/s]\n",
            "Epoch 2:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 2:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 2:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.20it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.65%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 3:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.07it/s]\n",
            "Epoch 3:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 3:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.17it/s]\n",
            "Epoch 3:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:40<00:43,  3.19it/s]\n",
            "Epoch 3:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 3:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 3:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 3:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.70%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 4:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.07it/s]\n",
            "Epoch 4:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 4:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.17it/s]\n",
            "Epoch 4:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:40<00:43,  3.18it/s]\n",
            "Epoch 4:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 162/268 [00:51<00:33,  3.19it/s]\n",
            "Epoch 4:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 4:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 228/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 4:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [01:21<00:02,  3.20it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.97%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 5:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.08it/s]\n",
            "Epoch 5:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.16it/s]\n",
            "Epoch 5:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.17it/s]\n",
            "Epoch 5:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:40<00:43,  3.18it/s]\n",
            "Epoch 5:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 162/268 [00:51<00:33,  3.19it/s]\n",
            "Epoch 5:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 5:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 228/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 5:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [01:21<00:02,  3.20it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.70%\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 6:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.08it/s]\n",
            "Epoch 6:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 6:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.18it/s]\n",
            "Epoch 6:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:40<00:43,  3.19it/s]\n",
            "Epoch 6:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 6:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 6:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 6:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.20it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.83%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 7:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.07it/s]\n",
            "Epoch 7:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 7:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.17it/s]\n",
            "Epoch 7:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:41<00:43,  3.18it/s]\n",
            "Epoch 7:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:51<00:43,  3.18it/s]\n",
            "Epoch 7:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 7:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.19it/s]\n",
            "Epoch 7:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 7:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.83%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 8:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.07it/s]\n",
            "Epoch 8:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 8:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.18it/s]\n",
            "Epoch 8:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:40<00:43,  3.19it/s]\n",
            "Epoch 8:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 8:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 8:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 8:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.95%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 9:  12%|‚ñà‚ñè        | 31/268 [00:10<01:17,  3.07it/s]\n",
            "Epoch 9:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:20<01:04,  3.15it/s]\n",
            "Epoch 9:  36%|‚ñà‚ñà‚ñà‚ñå      | 97/268 [00:30<00:53,  3.18it/s]\n",
            "Epoch 9:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:40<00:43,  3.19it/s]\n",
            "Epoch 9:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 163/268 [00:51<00:32,  3.19it/s]\n",
            "Epoch 9:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [01:01<00:22,  3.20it/s]\n",
            "Epoch 9:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 229/268 [01:11<00:12,  3.20it/s]\n",
            "Epoch 9:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [01:22<00:01,  3.20it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [01:23<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 8-8, summary, console lines 61-63\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñÖ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 9\n",
            "wandb: val_acc 98.53968\n",
            "wandb: \n",
            "wandb: üöÄ View run royal-gorge-23 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/yjfbolr4\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 8 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_092315-yjfbolr4/logs\n",
            "   Val Acc: 98.54%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: SimpleCNN_RealOnly\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run yjgvfc01\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_093816-yjgvfc01\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run dazzling-dream-24\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/yjgvfc01\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: simple_cnn\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 237\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 1:  25%|‚ñà‚ñà‚ñç       | 59/237 [00:10<00:30,  5.85it/s]\n",
            "Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 124/237 [00:20<00:18,  6.23it/s]\n",
            "Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 189/237 [00:30<00:07,  6.33it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:37<00:00,  6.28it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.73%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 2:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:26,  6.57it/s]\n",
            "Epoch 2:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/237 [00:20<00:15,  6.63it/s]\n",
            "Epoch 2:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 200/237 [00:30<00:05,  6.62it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.62it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.87%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 3:  27%|‚ñà‚ñà‚ñã       | 65/237 [00:10<00:26,  6.38it/s]\n",
            "Epoch 3:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 132/237 [00:20<00:15,  6.57it/s]\n",
            "Epoch 3:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 199/237 [00:30<00:05,  6.58it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.59it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.10%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 4:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:10<00:27,  6.37it/s]\n",
            "Epoch 4:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:20<00:16,  6.44it/s]\n",
            "Epoch 4:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 196/237 [00:30<00:06,  6.54it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:36<00:00,  6.53it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.30%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 5:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:10<00:27,  6.40it/s]\n",
            "Epoch 5:  27%|‚ñà‚ñà‚ñã       | 64/237 [00:20<00:27,  6.40it/s]\n",
            "Epoch 5:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:20<00:16,  6.40it/s]\n",
            "Epoch 5:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 196/237 [00:30<00:06,  6.53it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:36<00:00,  6.53it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.62%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 6:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:10<00:27,  6.25it/s]\n",
            "Epoch 6:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 129/237 [00:20<00:16,  6.40it/s]\n",
            "Epoch 6:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 195/237 [00:30<00:06,  6.46it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:36<00:00,  6.48it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.97%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 7:  27%|‚ñà‚ñà‚ñã       | 63/237 [00:10<00:27,  6.30it/s]\n",
            "Epoch 7:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 130/237 [00:20<00:16,  6.52it/s]\n",
            "Epoch 7:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 198/237 [00:30<00:05,  6.62it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.62it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.00%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 8:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:26,  6.54it/s]\n",
            "Epoch 8:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/237 [00:20<00:15,  6.58it/s]\n",
            "Epoch 8:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 201/237 [00:30<00:05,  6.64it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.66it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.76%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 9:  27%|‚ñà‚ñà‚ñã       | 65/237 [00:10<00:26,  6.40it/s]\n",
            "Epoch 9:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/237 [00:20<00:15,  6.59it/s]\n",
            "Epoch 9:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 201/237 [00:30<00:05,  6.68it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.68it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.79%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 10:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:26,  6.55it/s]\n",
            "Epoch 10:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 134/237 [00:20<00:15,  6.69it/s]\n",
            "Epoch 10:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 202/237 [00:30<00:05,  6.69it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.68it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.97%\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 11:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:26,  6.52it/s]\n",
            "Epoch 11:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 133/237 [00:20<00:15,  6.61it/s]\n",
            "Epoch 11:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 200/237 [00:30<00:05,  6.65it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.62it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.68%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 12:  28%|‚ñà‚ñà‚ñä       | 67/237 [00:10<00:25,  6.59it/s]\n",
            "Epoch 12:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 135/237 [00:20<00:15,  6.69it/s]\n",
            "Epoch 12:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 203/237 [00:30<00:05,  6.74it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.73it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.59%\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 13:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:25,  6.59it/s]\n",
            "Epoch 13:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 134/237 [00:20<00:15,  6.68it/s]\n",
            "Epoch 13:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 202/237 [00:30<00:05,  6.68it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.64it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.73%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/237 [00:00<?, ?it/s]\n",
            "Epoch 14:  28%|‚ñà‚ñà‚ñä       | 66/237 [00:10<00:26,  6.58it/s]\n",
            "Epoch 14:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 134/237 [00:20<00:15,  6.69it/s]\n",
            "Epoch 14:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 202/237 [00:30<00:05,  6.71it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237/237 [00:35<00:00,  6.72it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 237 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 13-13, summary, console lines 89-91\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÑ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 14\n",
            "wandb: val_acc 93.25397\n",
            "wandb: \n",
            "wandb: üöÄ View run dazzling-dream-24 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/yjgvfc01\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 18 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_093816-yjgvfc01/logs\n",
            "   Val Acc: 93.25%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: SimpleCNN_Synthetic\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run em9khk0r\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_095021-em9khk0r\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run fiery-sky-25\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/em9khk0r\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: simple_cnn\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 17124 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 268\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 1:  21%|‚ñà‚ñà        | 56/268 [00:10<00:38,  5.57it/s]\n",
            "Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 120/268 [00:20<00:24,  6.05it/s]\n",
            "Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 186/268 [00:30<00:13,  6.24it/s]\n",
            "Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 251/268 [00:40<00:02,  6.33it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:43<00:00,  6.17it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.13%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 2:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.29it/s]\n",
            "Epoch 2:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:20<00:32,  6.29it/s]\n",
            "Epoch 2:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:20<00:21,  6.51it/s]\n",
            "Epoch 2:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 197/268 [00:30<00:10,  6.54it/s]\n",
            "Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 264/268 [00:40<00:00,  6.55it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:40<00:00,  6.55it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.17%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 3:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.23it/s]\n",
            "Epoch 3:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 128/268 [00:20<00:21,  6.38it/s]\n",
            "Epoch 3:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 194/268 [00:30<00:11,  6.46it/s]\n",
            "Epoch 3:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 260/268 [00:40<00:01,  6.49it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.45it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.05%\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 4:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:31,  6.38it/s]\n",
            "Epoch 4:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.44it/s]\n",
            "Epoch 4:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.47it/s]\n",
            "Epoch 4:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 260/268 [00:40<00:01,  6.48it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.47it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.62%\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 5:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.36it/s]\n",
            "Epoch 5:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.44it/s]\n",
            "Epoch 5:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.50it/s]\n",
            "Epoch 5:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.50it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.49it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.08%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 6:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.26it/s]\n",
            "Epoch 6:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.45it/s]\n",
            "Epoch 6:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.48it/s]\n",
            "Epoch 6:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [00:40<00:00,  6.57it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.52it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.76%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 7:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.37it/s]\n",
            "Epoch 7:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.43it/s]\n",
            "Epoch 7:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 194/268 [00:30<00:11,  6.43it/s]\n",
            "Epoch 7:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 260/268 [00:40<00:01,  6.48it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.48it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.02%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 8:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:33,  6.20it/s]\n",
            "Epoch 8:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 128/268 [00:20<00:21,  6.36it/s]\n",
            "Epoch 8:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 193/268 [00:30<00:11,  6.34it/s]\n",
            "Epoch 8:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 257/268 [00:40<00:01,  6.33it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:42<00:00,  6.33it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.10%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 9:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.29it/s]\n",
            "Epoch 9:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:20<00:21,  6.42it/s]\n",
            "Epoch 9:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [00:30<00:11,  6.49it/s]\n",
            "Epoch 9:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [00:40<00:00,  6.49it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.46it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.16%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 10:  23%|‚ñà‚ñà‚ñé       | 62/268 [00:10<00:33,  6.16it/s]\n",
            "Epoch 10:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 126/268 [00:20<00:22,  6.28it/s]\n",
            "Epoch 10:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 193/268 [00:30<00:11,  6.46it/s]\n",
            "Epoch 10:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 193/268 [00:40<00:11,  6.46it/s]\n",
            "Epoch 10:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 260/268 [00:40<00:01,  6.47it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.44it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.63%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 11:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.28it/s]\n",
            "Epoch 11:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.43it/s]\n",
            "Epoch 11:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.48it/s]\n",
            "Epoch 11:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.49it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.47it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.16%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 12:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:31,  6.38it/s]\n",
            "Epoch 12:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:20<00:21,  6.49it/s]\n",
            "Epoch 12:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 197/268 [00:30<00:10,  6.54it/s]\n",
            "Epoch 12:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 264/268 [00:40<00:00,  6.56it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:40<00:00,  6.55it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.68%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 13:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.22it/s]\n",
            "Epoch 13:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.40it/s]\n",
            "Epoch 13:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.49it/s]\n",
            "Epoch 13:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.48it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.47it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.65%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 14:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:32,  6.26it/s]\n",
            "Epoch 14:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.45it/s]\n",
            "Epoch 14:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.48it/s]\n",
            "Epoch 14:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.48it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.47it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.94%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 15:  24%|‚ñà‚ñà‚ñé       | 63/268 [00:10<00:33,  6.21it/s]\n",
            "Epoch 15:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 128/268 [00:20<00:22,  6.36it/s]\n",
            "Epoch 15:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.45it/s]\n",
            "Epoch 15:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.43it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.42it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 95.02%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 16:  23%|‚ñà‚ñà‚ñé       | 62/268 [00:10<00:33,  6.18it/s]\n",
            "Epoch 16:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 128/268 [00:20<00:21,  6.40it/s]\n",
            "Epoch 16:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 194/268 [00:30<00:11,  6.41it/s]\n",
            "Epoch 16:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 259/268 [00:40<00:01,  6.38it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.38it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.95%\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 17:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.34it/s]\n",
            "Epoch 17:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:20<00:21,  6.47it/s]\n",
            "Epoch 17:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 197/268 [00:30<00:10,  6.57it/s]\n",
            "Epoch 17:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 264/268 [00:40<00:00,  6.49it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.51it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 95.27%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 18:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.33it/s]\n",
            "Epoch 18:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.38it/s]\n",
            "Epoch 18:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 194/268 [00:30<00:11,  6.38it/s]\n",
            "Epoch 18:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 260/268 [00:40<00:01,  6.44it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.44it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.59%\n",
            "DEBUG: Start Epoch 19/20\n",
            "\n",
            "Epoch 19:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 19:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:31,  6.40it/s]\n",
            "Epoch 19:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 129/268 [00:20<00:21,  6.42it/s]\n",
            "Epoch 19:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 195/268 [00:30<00:11,  6.47it/s]\n",
            "Epoch 19:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 261/268 [00:40<00:01,  6.42it/s]\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.43it/s]\n",
            "DEBUG: Epoch 19 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 95.38%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 20/20\n",
            "\n",
            "Epoch 20:   0%|          | 0/268 [00:00<?, ?it/s]\n",
            "Epoch 20:  24%|‚ñà‚ñà‚ñç       | 64/268 [00:10<00:32,  6.32it/s]\n",
            "Epoch 20:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 130/268 [00:20<00:21,  6.43it/s]\n",
            "Epoch 20:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 196/268 [00:30<00:11,  6.39it/s]\n",
            "Epoch 20:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 262/268 [00:40<00:00,  6.45it/s]\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268/268 [00:41<00:00,  6.44it/s]\n",
            "DEBUG: Epoch 20 Training Done. Processed 268 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading config.yaml\n",
            "wandb: uploading history steps 19-19, summary, console lines 123-124\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 20\n",
            "wandb: val_acc 95.14286\n",
            "wandb: \n",
            "wandb: üöÄ View run fiery-sky-25 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/em9khk0r\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 22 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_095021-em9khk0r/logs\n",
            "   Val Acc: 95.14%\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: EfficientNet_RealOnly\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run 7bvcj8zj\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_100920-7bvcj8zj\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run swift-shape-26\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/7bvcj8zj\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: efficientnet\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 473\n",
            "DEBUG: Initializing Model...\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "\n",
            "  0%|          | 0.00/20.5M [00:00<?, ?B/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 232MB/s]\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 1/473 [00:14<1:51:00, 14.11s/it]\n",
            "Epoch 1:  25%|‚ñà‚ñà‚ñç       | 116/473 [00:24<01:01,  5.82it/s]\n",
            "Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 231/473 [00:34<00:29,  8.17it/s]\n",
            "Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 346/473 [00:44<00:13,  9.38it/s]\n",
            "Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 461/473 [00:54<00:01, 10.11it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [01:07<00:00,  6.98it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.48%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 2:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.23it/s]\n",
            "Epoch 2:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.36it/s]\n",
            "Epoch 2:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.38it/s]\n",
            "Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.39it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.37it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.71%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 3:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.27it/s]\n",
            "Epoch 3:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.42it/s]\n",
            "Epoch 3:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 3:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.44it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.70%\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 4:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.25it/s]\n",
            "Epoch 4:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 4:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.41it/s]\n",
            "Epoch 4:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.44it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.95%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 5:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.23it/s]\n",
            "Epoch 5:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.34it/s]\n",
            "Epoch 5:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.39it/s]\n",
            "Epoch 5:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.41it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.39it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.94%\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 6:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.25it/s]\n",
            "Epoch 6:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.37it/s]\n",
            "Epoch 6:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.42it/s]\n",
            "Epoch 6:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.45it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.62%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 7:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.21it/s]\n",
            "Epoch 7:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 7:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 7:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.92%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 8:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.22it/s]\n",
            "Epoch 8:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 8:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.45it/s]\n",
            "Epoch 8:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:40<00:11, 11.45it/s]\n",
            "Epoch 8:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 461/473 [00:40<00:01, 11.48it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.44it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.98%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 9:  23%|‚ñà‚ñà‚ñé       | 111/473 [00:10<00:32, 11.10it/s]\n",
            "Epoch 9:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 227/473 [00:20<00:21, 11.34it/s]\n",
            "Epoch 9:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.40it/s]\n",
            "Epoch 9:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.43it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.39it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.89%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 10:  23%|‚ñà‚ñà‚ñé       | 111/473 [00:10<00:32, 11.01it/s]\n",
            "Epoch 10:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 225/473 [00:20<00:22, 11.23it/s]\n",
            "Epoch 10:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 340/473 [00:30<00:11, 11.35it/s]\n",
            "Epoch 10:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 455/473 [00:40<00:01, 11.40it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.35it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.06%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 11:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.24it/s]\n",
            "Epoch 11:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 11:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.43it/s]\n",
            "Epoch 11:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.45it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.94%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 12:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.25it/s]\n",
            "Epoch 12:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 12:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 12:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.44it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.10%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 13:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.25it/s]\n",
            "Epoch 13:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 13:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 13:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.45it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.97%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 14:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.25it/s]\n",
            "Epoch 14:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 14:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.45it/s]\n",
            "Epoch 14:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 461/473 [00:40<00:01, 11.47it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.44it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.03%\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 15:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.25it/s]\n",
            "Epoch 15:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 15:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 15:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.03%\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 16:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:31, 11.26it/s]\n",
            "Epoch 16:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 16:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 16:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.90%\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 17:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.24it/s]\n",
            "Epoch 17:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 17:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 17:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.27%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 18:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.25it/s]\n",
            "Epoch 18:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 18:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.43it/s]\n",
            "Epoch 18:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.45it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.24%\n",
            "DEBUG: Start Epoch 19/20\n",
            "\n",
            "Epoch 19:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 19:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.24it/s]\n",
            "Epoch 19:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 228/473 [00:20<00:21, 11.39it/s]\n",
            "Epoch 19:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 343/473 [00:30<00:11, 11.43it/s]\n",
            "Epoch 19:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 458/473 [00:40<00:01, 11.45it/s]\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 19 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.21%\n",
            "DEBUG: Start Epoch 20/20\n",
            "\n",
            "Epoch 20:   0%|          | 0/473 [00:00<?, ?it/s]\n",
            "Epoch 20:  24%|‚ñà‚ñà‚ñç       | 113/473 [00:10<00:32, 11.25it/s]\n",
            "Epoch 20:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 229/473 [00:20<00:21, 11.40it/s]\n",
            "Epoch 20:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 345/473 [00:30<00:11, 11.44it/s]\n",
            "Epoch 20:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 460/473 [00:40<00:01, 11.46it/s]\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 473/473 [00:41<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 20 Training Done. Processed 473 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 19-19, summary, console lines 119-120\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñà‚ñá‚ñá\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 20\n",
            "wandb: val_acc 99.15873\n",
            "wandb: \n",
            "wandb: üöÄ View run swift-shape-26 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/7bvcj8zj\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_100920-7bvcj8zj/logs\n",
            "   Val Acc: 99.16%\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING PIPELINE: EfficientNet_Synthetic\n",
            "============================================================\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run 0pts56y3\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251204_102842-0pts56y3\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run faithful-dream-27\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/0pts56y3\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: efficientnet\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 50.0% of Real Data.\n",
            "   Real Training Samples: 15124\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 17124 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 536\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 1:   0%|          | 1/536 [00:13<2:00:54, 13.56s/it]\n",
            "Epoch 1:  22%|‚ñà‚ñà‚ñè       | 117/536 [00:23<01:10,  5.97it/s]\n",
            "Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 233/536 [00:33<00:36,  8.31it/s]\n",
            "Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 348/536 [00:43<00:19,  9.49it/s]\n",
            "Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 463/536 [00:53<00:07, 10.17it/s]\n",
            "Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 463/536 [01:10<00:07, 10.17it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [01:12<00:00,  7.17it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [01:12<00:00,  7.40it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.30%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 2:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.21it/s]\n",
            "Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.34it/s]\n",
            "Epoch 2:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.37it/s]\n",
            "Epoch 2:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.39it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:47<00:00, 11.37it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.60%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 3:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.25it/s]\n",
            "Epoch 3:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 229/536 [00:20<00:26, 11.40it/s]\n",
            "Epoch 3:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 345/536 [00:30<00:16, 11.40it/s]\n",
            "Epoch 3:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 460/536 [00:40<00:06, 11.42it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.41it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.70%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 4:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 4:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.34it/s]\n",
            "Epoch 4:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.40it/s]\n",
            "Epoch 4:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.42it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.41it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.48%\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 5:  21%|‚ñà‚ñà        | 112/536 [00:10<00:37, 11.17it/s]\n",
            "Epoch 5:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 227/536 [00:20<00:27, 11.36it/s]\n",
            "Epoch 5:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 342/536 [00:30<00:17, 11.41it/s]\n",
            "Epoch 5:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 457/536 [00:40<00:06, 11.43it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.41it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.86%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 6:  21%|‚ñà‚ñà        | 112/536 [00:10<00:37, 11.16it/s]\n",
            "Epoch 6:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 227/536 [00:20<00:27, 11.35it/s]\n",
            "Epoch 6:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 342/536 [00:30<00:17, 11.40it/s]\n",
            "Epoch 6:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 457/536 [00:40<00:06, 11.43it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.41it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.90%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 7:  21%|‚ñà‚ñà        | 110/536 [00:10<00:38, 10.95it/s]\n",
            "Epoch 7:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 225/536 [00:20<00:27, 11.26it/s]\n",
            "Epoch 7:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 340/536 [00:30<00:17, 11.30it/s]\n",
            "Epoch 7:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 455/536 [00:40<00:07, 11.37it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:47<00:00, 11.34it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.90%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 8:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.24it/s]\n",
            "Epoch 8:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.39it/s]\n",
            "Epoch 8:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.43it/s]\n",
            "Epoch 8:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.79%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 9:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.22it/s]\n",
            "Epoch 9:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.37it/s]\n",
            "Epoch 9:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.41it/s]\n",
            "Epoch 9:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.43it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.19%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 10:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 10:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 10:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.41it/s]\n",
            "Epoch 10:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.43it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.83%\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 11:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 11:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.39it/s]\n",
            "Epoch 11:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.43it/s]\n",
            "Epoch 11:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.86%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 12:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 12:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 12:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.42it/s]\n",
            "Epoch 12:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.21%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 13:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 13:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 13:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.41it/s]\n",
            "Epoch 13:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.43it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.14%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 14:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.23it/s]\n",
            "Epoch 14:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 14:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.42it/s]\n",
            "Epoch 14:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.19%\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 15:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.22it/s]\n",
            "Epoch 15:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 15:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.42it/s]\n",
            "Epoch 15:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.42it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.83%\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 16:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.24it/s]\n",
            "Epoch 16:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.38it/s]\n",
            "Epoch 16:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.42it/s]\n",
            "Epoch 16:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 99.16%\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/536 [00:00<?, ?it/s]\n",
            "Epoch 17:  21%|‚ñà‚ñà        | 113/536 [00:10<00:37, 11.24it/s]\n",
            "Epoch 17:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 228/536 [00:20<00:27, 11.39it/s]\n",
            "Epoch 17:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 343/536 [00:30<00:16, 11.43it/s]\n",
            "Epoch 17:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 458/536 [00:40<00:06, 11.44it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 536/536 [00:46<00:00, 11.43it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 536 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading wandb-summary.json; uploading output.log\n",
            "wandb: uploading config.yaml\n",
            "wandb: uploading history steps 16-16, summary, console lines 104-106\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñÖ‚ñà‚ñÜ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 17\n",
            "wandb: val_acc 98.88889\n",
            "wandb: \n",
            "wandb: üöÄ View run faithful-dream-27 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/0pts56y3\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251204_102842-0pts56y3/logs\n",
            "   Val Acc: 98.89%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "Training Complete.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Basic settings for the project\n",
        "# Make sure you are logged in with wandb.login() before running this\n",
        "PROJECT = \"wildfire-final-benchmark\"\n",
        "ENTITY = wandb.Api().default_entity\n",
        "\n",
        "# This is where the repository is cloned in Colab\n",
        "REPO_DIR = \"/content/WildfireDetectionDL\"\n",
        "\n",
        "# These are the exact configurations we want to benchmark\n",
        "TARGETS = [\n",
        "    (\"ResNet50\", False), (\"ResNet50\", True),\n",
        "    (\"SimpleCNN\", False), (\"SimpleCNN\", True),\n",
        "    (\"EfficientNet\", False), (\"EfficientNet\", True),\n",
        "]\n",
        "\n",
        "def parse_metrics(output_text):\n",
        "    # We use regex here to pull the numbers out of the console output\n",
        "    # This expects the test.py script to print lines like \"Accuracy: 0.95\"\n",
        "    metrics = {}\n",
        "    patterns = {\n",
        "        \"Accuracy\": r\"Accuracy:\\s+([0-9.]+)\",\n",
        "        \"Precision\": r\"Precision:\\s+([0-9.]+)\",\n",
        "        \"Recall\": r\"Recall:\\s+([0-9.]+)\",\n",
        "        \"F1-Score\": r\"F1-Score:\\s+([0-9.]+)\"\n",
        "    }\n",
        "\n",
        "    for key, pattern in patterns.items():\n",
        "        match = re.search(pattern, output_text)\n",
        "        if match:\n",
        "            metrics[key] = float(match.group(1))\n",
        "        else:\n",
        "            # If we can't find the metric, default to 0 so the script doesn't crash\n",
        "            metrics[key] = 0.0\n",
        "    return metrics\n",
        "\n",
        "def run_colab_testing_pipeline():\n",
        "    api = wandb.Api()\n",
        "    results_data = []\n",
        "\n",
        "    print(f\"Starting Benchmark Evaluation on Project: {PROJECT}\\n\")\n",
        "\n",
        "    for model_label, use_synthetic in TARGETS:\n",
        "        # Recreate the run name so we can find it in the cloud.\n",
        "        # This matches the +wandb.name argument we used during training.\n",
        "        run_name = f\"{model_label}_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"PROCESSING: {run_name}\")\n",
        "\n",
        "        # Search for the run in WandB history\n",
        "        runs = api.runs(f\"{ENTITY}/{PROJECT}\", filters={\"display_name\": run_name, \"state\": \"finished\"})\n",
        "\n",
        "        if len(runs) == 0:\n",
        "            print(f\"[ERROR] Could not find a finished run named '{run_name}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # If there are duplicates, the first one is usually the most recent\n",
        "        target_run = runs[0]\n",
        "        print(f\" >> Found Run ID: {target_run.id}\")\n",
        "\n",
        "        # Check if this run actually has a model saved\n",
        "        try:\n",
        "            logged_artifacts = target_run.logged_artifacts()\n",
        "            model_artifacts = [a for a in logged_artifacts if a.type == 'model']\n",
        "\n",
        "            if not model_artifacts:\n",
        "                print(f\" >> [ERROR] Run exists but has no model artifact. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            artifact = model_artifacts[0]\n",
        "            print(f\" >> Downloading Artifact: {artifact.name}\")\n",
        "\n",
        "            # Download the weights to the local Colab disk\n",
        "            download_dir = artifact.download()\n",
        "\n",
        "            # We need the absolute path because the subprocess runs in a different folder\n",
        "            weight_path = os.path.abspath(os.path.join(download_dir, \"model_weights.pth\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" >> [ERROR] Problem downloading artifact: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Now we figure out the architecture details from the config\n",
        "        # This is important so we don't accidentally load a ResNet into a SimpleCNN\n",
        "        train_config = target_run.config\n",
        "        try:\n",
        "            # Sometimes config is nested (model -> dropout), sometimes flat (model.dropout)\n",
        "            # We try both ways to be safe\n",
        "            if 'model' in train_config and isinstance(train_config['model'], dict):\n",
        "                model_dropout = train_config['model'].get('dropout', 0.0)\n",
        "                model_arch_name = train_config['model'].get('name')\n",
        "            else:\n",
        "                model_dropout = train_config.get('model.dropout', 0.0)\n",
        "                model_arch_name = train_config.get('model.name')\n",
        "\n",
        "            # If the config is missing the name, assume it matches our loop label\n",
        "            if not model_arch_name:\n",
        "                model_arch_name = model_label.lower()\n",
        "\n",
        "        except Exception:\n",
        "            # If everything fails, use safe defaults\n",
        "            print(\" >> [WARNING] Could not read config. Using defaults.\")\n",
        "            model_dropout = 0.5\n",
        "            model_arch_name = model_label.lower()\n",
        "\n",
        "        print(f\" >> Configuration inferred: Arch={model_arch_name}, Dropout={model_dropout}\")\n",
        "\n",
        "        # Prepare the command to run test.py\n",
        "        cmd = [\n",
        "            sys.executable, \"test.py\",\n",
        "            f\"model.name={model_arch_name}\",\n",
        "            f\"model.dropout={model_dropout}\",\n",
        "            f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "            \"wandb.mode=disabled\",\n",
        "            f\"+model_path={weight_path}\"\n",
        "        ]\n",
        "\n",
        "        print(\" >> Starting test execution...\")\n",
        "\n",
        "        # Using Popen allows us to see the output line by line as it happens\n",
        "        try:\n",
        "            process = subprocess.Popen(\n",
        "                cmd,\n",
        "                cwd=REPO_DIR,    # Run inside the repo folder so imports work\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.STDOUT, # Merge errors into main output\n",
        "                text=True,\n",
        "                bufsize=1,\n",
        "                universal_newlines=True\n",
        "            )\n",
        "\n",
        "            # We need to capture the full output to parse metrics later,\n",
        "            # but we also want to print it now so the user sees progress.\n",
        "            full_console_output = \"\"\n",
        "\n",
        "            for line in process.stdout:\n",
        "                print(line, end=\"\")\n",
        "                full_console_output += line\n",
        "\n",
        "            process.wait()\n",
        "\n",
        "            if process.returncode == 0:\n",
        "                print(\"\\n >> [SUCCESS] Test finished.\")\n",
        "\n",
        "                # Extract the numbers from the text we just captured\n",
        "                metrics = parse_metrics(full_console_output)\n",
        "\n",
        "                entry = {\n",
        "                    \"Model\": model_label,\n",
        "                    \"Data\": \"Synthetic\" if use_synthetic else \"RealOnly\",\n",
        "                    \"Run_ID\": target_run.id,\n",
        "                    **metrics\n",
        "                }\n",
        "                results_data.append(entry)\n",
        "            else:\n",
        "                print(\"\\n >> [FAILURE] The test script crashed.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" >> [ERROR] subprocess failed: {e}\")\n",
        "\n",
        "    # Finally, save everything to a CSV file\n",
        "    if results_data:\n",
        "        df = pd.DataFrame(results_data)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"FINAL BENCHMARK RESULTS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(df)\n",
        "        df.to_csv(\"benchmark_results.csv\", index=False)\n",
        "        print(\"\\nResults saved to benchmark_results.csv\")\n",
        "    else:\n",
        "        print(\"\\nNo results gathered.\")\n",
        "\n",
        "# Run the function\n",
        "if __name__ == \"__main__\":\n",
        "    run_colab_testing_pipeline()"
      ],
      "metadata": {
        "id": "XzT7nl5MA7cO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba4a37e-cdba-4037-f68e-b826bcecb6d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Benchmark Evaluation on Project: wildfire-final-benchmark\n",
            "\n",
            "============================================================\n",
            "PROCESSING: ResNet50_RealOnly\n",
            " >> Found Run ID: strm81l9\n",
            " >> Downloading Artifact: model-resnet50-strm81l9:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-resnet50-strm81l9:v0', 90.00MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.6 (161.1MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=resnet50, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: resnet50\n",
            "DEBUG: Processing 320 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9876\n",
            "Precision: 0.9930\n",
            "Recall:    0.9845\n",
            "F1-Score:  0.9887\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "============================================================\n",
            "PROCESSING: ResNet50_Synthetic\n",
            " >> Found Run ID: yjfbolr4\n",
            " >> Downloading Artifact: model-resnet50-yjfbolr4:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-resnet50-yjfbolr4:v0', 90.00MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.3 (291.4MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=resnet50, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: resnet50\n",
            "DEBUG: Processing 320 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9843\n",
            "Precision: 0.9965\n",
            "Recall:    0.9750\n",
            "F1-Score:  0.9856\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "============================================================\n",
            "PROCESSING: SimpleCNN_RealOnly\n",
            " >> Found Run ID: yjgvfc01\n",
            " >> Downloading Artifact: model-simple_cnn-yjgvfc01:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-simple_cnn-yjgvfc01:v0', 196.37MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.3 (571.0MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=simple_cnn, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: simple_cnn\n",
            "DEBUG: Processing 10 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9252\n",
            "Precision: 0.9241\n",
            "Recall:    0.9419\n",
            "F1-Score:  0.9330\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "============================================================\n",
            "PROCESSING: SimpleCNN_Synthetic\n",
            " >> Found Run ID: em9khk0r\n",
            " >> Downloading Artifact: model-simple_cnn-em9khk0r:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-simple_cnn-em9khk0r:v0', 196.37MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.3 (624.8MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=simple_cnn, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: simple_cnn\n",
            "DEBUG: Processing 10 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9284\n",
            "Precision: 0.9121\n",
            "Recall:    0.9632\n",
            "F1-Score:  0.9369\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "============================================================\n",
            "PROCESSING: EfficientNet_RealOnly\n",
            " >> Found Run ID: 7bvcj8zj\n",
            " >> Downloading Artifact: model-efficientnet-7bvcj8zj:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=efficientnet, Dropout=0.2\n",
            " >> Starting test execution...\n",
            "Testing Model: efficientnet\n",
            "DEBUG: Processing 360 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9860\n",
            "Precision: 0.9840\n",
            "Recall:    0.9908\n",
            "F1-Score:  0.9874\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "============================================================\n",
            "PROCESSING: EfficientNet_Synthetic\n",
            " >> Found Run ID: 0pts56y3\n",
            " >> Downloading Artifact: model-efficientnet-0pts56y3:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=efficientnet, Dropout=0.2\n",
            " >> Starting test execution...\n",
            "Testing Model: efficientnet\n",
            "DEBUG: Processing 360 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9852\n",
            "Precision: 0.9832\n",
            "Recall:    0.9902\n",
            "F1-Score:  0.9867\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "\n",
            "============================================================\n",
            "FINAL BENCHMARK RESULTS\n",
            "============================================================\n",
            "          Model       Data    Run_ID  Accuracy  Precision  Recall  F1-Score\n",
            "0      ResNet50   RealOnly  strm81l9    0.9876     0.9930  0.9845    0.9887\n",
            "1      ResNet50  Synthetic  yjfbolr4    0.9843     0.9965  0.9750    0.9856\n",
            "2     SimpleCNN   RealOnly  yjgvfc01    0.9252     0.9241  0.9419    0.9330\n",
            "3     SimpleCNN  Synthetic  em9khk0r    0.9284     0.9121  0.9632    0.9369\n",
            "4  EfficientNet   RealOnly  7bvcj8zj    0.9860     0.9840  0.9908    0.9874\n",
            "5  EfficientNet  Synthetic  0pts56y3    0.9852     0.9832  0.9902    0.9867\n",
            "\n",
            "Results saved to benchmark_results.csv\n"
          ]
        }
      ]
    }
  ]
}