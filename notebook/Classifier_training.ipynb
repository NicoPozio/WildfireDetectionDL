{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoPozio/WildfireDetectionDL/blob/main/notebook/Classifier_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NicoPozio/WildfireDetectionDL.git"
      ],
      "metadata": {
        "id": "NUhUF7tDYgzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2695833a-9090-439f-dd20-2d35fea359ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WildfireDetectionDL'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 239 (delta 21), reused 2 (delta 0), pack-reused 188 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 167.60 KiB | 12.89 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "repo_path = '/content/WildfireDetectionDL'\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "F1sXhKEnf1dO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Update Code\n",
        "import os\n",
        "\n",
        "REPO_PATH = \"/content/WildfireDetectionDL\"\n",
        "\n",
        "print(\"Syncing with GitHub...\")\n",
        "!cd {REPO_PATH} && git pull\n",
        "\n",
        "print(\"Code updated. You can now run the Sweep or Train cell immediately.\")"
      ],
      "metadata": {
        "id": "hpvQdBgJvSDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c535c90-4b19-4a9a-b6ed-471d9529a032"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syncing with GitHub...\n",
            "Already up to date.\n",
            "Code updated. You can now run the Sweep or Train cell immediately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Project Dependencies\n",
        "#hydra-core: Configuration management\n",
        "#wandb: Experiment tracking\n",
        "#omegaconf: Dict handling for Hydra\n",
        "!pip install -q hydra-core wandb omegaconf\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive Mounted\")\n"
      ],
      "metadata": {
        "id": "xYMO3qvxQo_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a304672f-465c-4777-ab18-61b92cb79584"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Google Drive Mounted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    #Fetch key from Colab Secrets\n",
        "    api_key = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    #Set as Environment Variable\n",
        "    #This ensures Hydra and subprocesses can find it automatically\n",
        "    os.environ[\"WANDB_API_KEY\"] = api_key\n",
        "\n",
        "    wandb.login()\n",
        "    print(\"Logged in to WandB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication Failed: {e}\")\n",
        "    print(\"Action Required: Go to the 'Secrets' tab (Key icon) on the left.\")\n",
        "    print(\"Add a new secret named 'WANDB_API_KEY' with your key from https://wandb.ai/authorize\")"
      ],
      "metadata": {
        "id": "HRabcBKtQqgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "082a6902-0d24-4f04-c0f9-0e53773e7c86"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpozioniccolo\u001b[0m (\u001b[33mpozioniccolo-sapienza-universit-di-roma\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in to WandB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we download the dataset, we check if the user has the data in its google drive, if not it's downloaded from a public link"
      ],
      "metadata": {
        "id": "Ti3-Olu9Xnqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "509SQeSJXm1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bddb45-ac03-47cb-f8b7-37fbb59f471f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42860/42860 [00:12<00:00, 3401.31files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Extracting synthetic_wildfire_2k.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2003/2003 [00:01<00:00, 1202.36files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Data Ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "from src.utils import extract_zip\n",
        "\n",
        "#Destination on Colab\n",
        "local_root = \"/content/data\"\n",
        "os.makedirs(local_root, exist_ok=True)\n",
        "!rm -rf {local_root}/*\n",
        "\n",
        "#Paths on drive (in case the CyclaGAN notebook is exectued)\n",
        "drive_dataset_path = \"/content/drive/MyDrive/Wildfire_Project/dataset.zip\"\n",
        "drive_synthetic_path = \"/content/drive/MyDrive/Wildfire_Project/synthetic_wildfire_2k.zip\"\n",
        "\n",
        "#Paths on Colab\n",
        "target_dataset_zip = os.path.join(local_root, \"dataset.zip\")\n",
        "target_synthetic_zip = os.path.join(local_root, \"synthetic_wildfire_2k.zip\")\n",
        "\n",
        "\n",
        "\n",
        "#Check if the file are present\n",
        "if os.path.isfile(drive_dataset_path) and os.path.isfile(drive_synthetic_path):\n",
        "    !cp \"{drive_dataset_path}\" \"{target_dataset_zip}\"\n",
        "    !cp \"{drive_synthetic_path}\" \"{target_synthetic_zip}\"\n",
        "\n",
        "else:\n",
        "\n",
        "    DATASET_ID = \"17KPBVodZkmBYqz7252mDk6hfY55eMU-Q\"\n",
        "    SYNTHETIC_ID = \"1KyI09FDCAkLp1BYO-VgD7zRMrtrl3anK\"\n",
        "\n",
        "    gdown.download(id=DATASET_ID, output=target_dataset_zip, quiet=False)\n",
        "\n",
        "    gdown.download(id=SYNTHETIC_ID, output=target_synthetic_zip, quiet=False)\n",
        "\n",
        "\n",
        "if os.path.exists(target_dataset_zip) and os.path.exists(target_synthetic_zip):\n",
        "    if os.path.getsize(target_dataset_zip) > 0:\n",
        "        extract_zip(target_dataset_zip, local_root)\n",
        "    if os.path.getsize(target_synthetic_zip) > 0:\n",
        "        extract_zip(target_synthetic_zip, local_root)\n",
        "    print(\"Data Ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define your data root\n",
        "DATA_ROOT = \"/content/data\"\n",
        "\n",
        "print(f\"Scanning {DATA_ROOT} for corrupt images...\")\n",
        "\n",
        "corrupt_count = 0\n",
        "for root, dirs, files in os.walk(DATA_ROOT):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            file_path = os.path.join(root, filename)\n",
        "            try:\n",
        "                # Try to fully load the image bytes\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()\n",
        "            except OSError:\n",
        "                print(f\"Found corrupt image: {file_path}\")\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                    print(f\"Deleted {filename}\")\n",
        "                    corrupt_count += 1\n",
        "                except:\n",
        "                    print(f\"Could not delete {filename}\")\n",
        "\n",
        "print(f\"\\nScan Complete. Removed {corrupt_count} corrupt files.\")"
      ],
      "metadata": {
        "id": "pNVIFW9gqYb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b16bf8-36a1-45e2-bae6-e591c6fc6023"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning /content/data for corrupt images...\n",
            "Found corrupt image: /content/data/dataset/test/wildfire/-73.15884,46.38819.jpg\n",
            "Deleted -73.15884,46.38819.jpg\n",
            "Found corrupt image: /content/data/dataset/train/nowildfire/-114.152378,51.027198.jpg\n",
            "Deleted -114.152378,51.027198.jpg\n",
            "\n",
            "Scan Complete. Removed 2 corrupt files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# 1. Define Paths Constants\n",
        "REPO_ROOT = \"/content/WildfireDetectionDL\"\n",
        "SWEEP_CONFIG_PATH = os.path.join(REPO_ROOT, \"conf\", \"sweep.yaml\")\n",
        "\n",
        "# 2. Validation\n",
        "if not os.path.exists(SWEEP_CONFIG_PATH):\n",
        "    print(f\"CRITICAL ERROR: Could not find sweep.yaml at {SWEEP_CONFIG_PATH}\")\n",
        "else:\n",
        "    print(f\"Registering Sweep from {SWEEP_CONFIG_PATH}\")\n",
        "\n",
        "    # 3. Register the sweep\n",
        "    result = subprocess.run(\n",
        "        [\"wandb\", \"sweep\", SWEEP_CONFIG_PATH],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        # CORRECTION: cwd must be the directory, not the file\n",
        "        cwd=REPO_ROOT\n",
        "    )\n",
        "\n",
        "    output_text = result.stderr + result.stdout\n",
        "    print(\"Raw Output:\", output_text)\n",
        "\n",
        "    # 4. Extract Sweep ID\n",
        "    sweep_id = None\n",
        "    for line in output_text.split('\\n'):\n",
        "        if \"wandb agent\" in line:\n",
        "            parts = line.strip().split(\"wandb agent \")\n",
        "            if len(parts) > 1:\n",
        "                sweep_id = parts[-1].strip()\n",
        "                break\n",
        "\n",
        "    # 5. Launch the Agent\n",
        "    if sweep_id:\n",
        "        print(f\"\\nSUCCESS: Detected Sweep ID: {sweep_id}\")\n",
        "        print(\"Starting Agent... (This will run multiple experiments)\")\n",
        "\n",
        "        # CORRECTION: We use the explicit REPO_ROOT variable defined at the top\n",
        "        !cd {REPO_ROOT} && wandb agent {sweep_id} --count 20\n",
        "    else:\n",
        "        print(\"\\nERROR: Could not find Sweep ID.\")"
      ],
      "metadata": {
        "id": "OE8v94eqa7zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0034c387-2513-46f8-ce33-59c101e3e97e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering Sweep from /content/WildfireDetectionDL/conf/sweep.yaml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-881789450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 3. Register the sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     result = subprocess.run(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"wandb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSWEEP_CONFIG_PATH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the sweep execution we found the best configuration for the neural networks, now we train the resnet50 using that parameters, we train using both synthetic+real, and only real"
      ],
      "metadata": {
        "id": "qLOavfqgtSmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Hyperparameter Configurations\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. ResNet50\n",
        "RESNET_CONFIG = [\n",
        "    \"model.name=resnet50\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=11\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00005836874490583941\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000621085260935666\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "# 2. SimpleCNN\n",
        "SIMPLE_CNN_CONFIG = [\n",
        "    \"model.name=simple_cnn\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=4\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00001349\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000823\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "# 3. EfficientNet\n",
        "EFFICIENTNET_CONFIG = [\n",
        "    \"model.name=efficientnet\",\n",
        "    \"model.dropout=0.2\",\n",
        "    \"dataset.augmentation.rotation_degrees=15\",\n",
        "    \"training.batch_size=32\",\n",
        "    \"training.learning_rate=0.0001\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.0\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "# Pipeline Logic\n",
        "\n",
        "def run_training_pipeline(model_label, use_synthetic, config_list):\n",
        "    run_id = f\"{model_label}_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STARTING TRAINING PIPELINE: {run_id}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    train_cmd = [\n",
        "        sys.executable, \"train.py\",\n",
        "        f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "        \"wandb.project=wildfire-final-benchmark\",\n",
        "        f\"+wandb.name={run_id}\"\n",
        "    ] + config_list\n",
        "\n",
        "    try:\n",
        "        process = subprocess.Popen(\n",
        "            train_cmd,\n",
        "            cwd=\"/content/WildfireDetectionDL\",\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        for line in process.stdout:\n",
        "            print(line, end=\"\")\n",
        "\n",
        "        process.wait()\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"\\nTRAINING FAILED: {run_id}\")\n",
        "            return False\n",
        "        else:\n",
        "            print(\"\\nTraining Complete.\")\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL ERROR: {e}\")\n",
        "        return False\n",
        "\n",
        "# Execution Loop\n",
        "# ResNet50\n",
        "run_training_pipeline(\"ResNet50\", False, RESNET_CONFIG)\n",
        "run_training_pipeline(\"ResNet50\", True, RESNET_CONFIG)\n",
        "\n",
        "# SimpleCNN\n",
        "run_training_pipeline(\"SimpleCNN\", False, SIMPLE_CNN_CONFIG)\n",
        "run_training_pipeline(\"SimpleCNN\", True, SIMPLE_CNN_CONFIG)\n",
        "\n",
        "# EfficientNet\n",
        "run_training_pipeline(\"EfficientNet\", False, EFFICIENTNET_CONFIG)\n",
        "run_training_pipeline(\"EfficientNet\", True, EFFICIENTNET_CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_3baXIXtQ20",
        "outputId": "d3fef36e-592d-47d7-d69d-52c73eeeb4f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING TRAINING PIPELINE: ResNet50_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run zlhelkcq\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_171856-zlhelkcq\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run astral-music-1\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/zlhelkcq\n",
            "Training on cuda using model: resnet50\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "BASELINE MODE: Using only Real data.\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "\n",
            "  0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
            "  5%|‚ñç         | 4.75M/97.8M [00:00<00:01, 48.9MB/s]\n",
            " 10%|‚ñâ         | 9.50M/97.8M [00:00<00:01, 48.4MB/s]\n",
            " 33%|‚ñà‚ñà‚ñà‚ñé      | 32.6M/97.8M [00:00<00:00, 135MB/s] \n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 56.1M/97.8M [00:00<00:00, 178MB/s]\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 79.5M/97.8M [00:00<00:00, 202MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 175MB/s]\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 1/20:  33%|‚ñà‚ñà‚ñà‚ñé      | 16/48 [00:10<00:20,  1.56it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:20<00:00,  2.42it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:20<00:00,  2.29it/s]\n",
            "   Train Loss: 0.3809 | Train Acc: 85.75%\n",
            "   Val Loss:   0.1903 | Val Acc:   92.38%\n",
            "   Validation Accuracy improved (0.00% -> 92.38%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 2/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.10it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.19it/s]\n",
            "   Train Loss: 0.1620 | Train Acc: 94.05%\n",
            "   Val Loss:   0.1130 | Val Acc:   96.25%\n",
            "   Validation Accuracy improved (92.38% -> 96.25%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 3/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.09it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.18it/s]\n",
            "   Train Loss: 0.1123 | Train Acc: 96.26%\n",
            "   Val Loss:   0.0881 | Val Acc:   96.97%\n",
            "   Validation Accuracy improved (96.25% -> 96.97%). Saving model...\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 4/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.16it/s]\n",
            "   Train Loss: 0.0754 | Train Acc: 97.32%\n",
            "   Val Loss:   0.0756 | Val Acc:   97.33%\n",
            "   Validation Accuracy improved (96.97% -> 97.33%). Saving model...\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 5/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "   Train Loss: 0.0630 | Train Acc: 97.78%\n",
            "   Val Loss:   0.0767 | Val Acc:   97.27%\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 6/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0424 | Train Acc: 98.68%\n",
            "   Val Loss:   0.0633 | Val Acc:   97.84%\n",
            "   Validation Accuracy improved (97.33% -> 97.84%). Saving model...\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 7/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0333 | Train Acc: 99.01%\n",
            "   Val Loss:   0.0664 | Val Acc:   97.73%\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 8/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0315 | Train Acc: 98.97%\n",
            "   Val Loss:   0.0744 | Val Acc:   97.68%\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 9/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0240 | Train Acc: 99.24%\n",
            "   Val Loss:   0.0763 | Val Acc:   97.40%\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 10/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0189 | Train Acc: 99.54%\n",
            "   Val Loss:   0.0707 | Val Acc:   97.48%\n",
            "\n",
            "Epoch 11/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 11/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0114 | Train Acc: 99.74%\n",
            "   Val Loss:   0.0667 | Val Acc:   97.98%\n",
            "   Validation Accuracy improved (97.84% -> 97.98%). Saving model...\n",
            "\n",
            "Epoch 12/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 12/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "   Train Loss: 0.0104 | Train Acc: 99.70%\n",
            "   Val Loss:   0.0638 | Val Acc:   98.13%\n",
            "   Validation Accuracy improved (97.98% -> 98.13%). Saving model...\n",
            "\n",
            "Epoch 13/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 13/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0107 | Train Acc: 99.64%\n",
            "   Val Loss:   0.0664 | Val Acc:   97.86%\n",
            "\n",
            "Epoch 14/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 14/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0124 | Train Acc: 99.60%\n",
            "   Val Loss:   0.0643 | Val Acc:   97.76%\n",
            "\n",
            "Epoch 15/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 15/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0124 | Train Acc: 99.77%\n",
            "   Val Loss:   0.0756 | Val Acc:   97.73%\n",
            "\n",
            "Epoch 16/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 16/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "   Train Loss: 0.0152 | Train Acc: 99.57%\n",
            "   Val Loss:   0.0715 | Val Acc:   97.81%\n",
            "\n",
            "Epoch 17/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 17/20:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "wandb: updating run metadata\n",
            "wandb: uploading wandb-summary.json; uploading output.log\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 16-16, summary, console lines 64-66\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb:   val_loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 17\n",
            "wandb:  train_acc 99.43783\n",
            "wandb: train_loss 0.01609\n",
            "wandb:    val_acc 97.85714\n",
            "wandb:   val_loss 0.07038\n",
            "wandb: \n",
            "wandb: üöÄ View run astral-music-1 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/zlhelkcq\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_171856-zlhelkcq/logs\n",
            "   Train Loss: 0.0161 | Train Acc: 99.44%\n",
            "   Val Loss:   0.0704 | Val Acc:   97.86%\n",
            "   Early Stopping Triggered.\n",
            "\n",
            "Training Complete.\n",
            "STARTING TRAINING PIPELINE: ResNet50_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run xlz83yql\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_172731-xlz83yql\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run peachy-cloud-2\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/xlz83yql\n",
            "Training on cuda using model: resnet50\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "AUGMENTATION ON: Injecting synthetic data...\n",
            "   -> Found 2000 synthetic wildfire images.\n",
            "   -> Merged Dataset Size: 5024\n",
            "   -> Synthetic Influence: 39.81% of training data\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 1/20:  25%|‚ñà‚ñà‚ñå       | 20/79 [00:10<00:29,  1.97it/s]\n",
            "Epoch 1/20:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/79 [00:20<00:09,  2.70it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:30<00:00,  2.62it/s]\n",
            "   Train Loss: 0.2770 | Train Acc: 89.97%\n",
            "   Val Loss:   0.1363 | Val Acc:   94.68%\n",
            "   Validation Accuracy improved (0.00% -> 94.68%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 2/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 2/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:20<00:04,  3.15it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.17it/s]\n",
            "   Train Loss: 0.0965 | Train Acc: 96.56%\n",
            "   Val Loss:   0.1039 | Val Acc:   95.95%\n",
            "   Validation Accuracy improved (94.68% -> 95.95%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 3/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.08it/s]\n",
            "Epoch 3/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:20<00:04,  3.15it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.17it/s]\n",
            "   Train Loss: 0.0656 | Train Acc: 97.69%\n",
            "   Val Loss:   0.0729 | Val Acc:   97.65%\n",
            "   Validation Accuracy improved (95.95% -> 97.65%). Saving model...\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 4/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 4/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.14it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.16it/s]\n",
            "   Train Loss: 0.0423 | Train Acc: 98.73%\n",
            "   Val Loss:   0.1047 | Val Acc:   96.19%\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 5/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 5/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:20<00:04,  3.15it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.17it/s]\n",
            "   Train Loss: 0.0316 | Train Acc: 98.95%\n",
            "   Val Loss:   0.0619 | Val Acc:   98.03%\n",
            "   Validation Accuracy improved (97.65% -> 98.03%). Saving model...\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 6/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 6/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.15it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.17it/s]\n",
            "   Train Loss: 0.0226 | Train Acc: 99.30%\n",
            "   Val Loss:   0.0698 | Val Acc:   97.56%\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 7/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 7/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.15it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.17it/s]\n",
            "   Train Loss: 0.0194 | Train Acc: 99.50%\n",
            "   Val Loss:   0.0848 | Val Acc:   97.35%\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 8/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 8/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:20<00:04,  3.15it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.16it/s]\n",
            "   Train Loss: 0.0167 | Train Acc: 99.44%\n",
            "   Val Loss:   0.0724 | Val Acc:   97.57%\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 9/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.07it/s]\n",
            "Epoch 9/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.14it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.16it/s]\n",
            "   Train Loss: 0.0113 | Train Acc: 99.60%\n",
            "   Val Loss:   0.0706 | Val Acc:   98.02%\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 10/20:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.08it/s]\n",
            "Epoch 10/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.15it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:24<00:00,  3.16it/s]\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 9-9, summary, console lines 41-43\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb:   val_loss ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 10\n",
            "wandb:  train_acc 99.76115\n",
            "wandb: train_loss 0.00906\n",
            "wandb:    val_acc 97.93651\n",
            "wandb:   val_loss 0.06802\n",
            "wandb: \n",
            "wandb: üöÄ View run peachy-cloud-2 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/xlz83yql\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_172731-xlz83yql/logs\n",
            "   Train Loss: 0.0091 | Train Acc: 99.76%\n",
            "   Val Loss:   0.0680 | Val Acc:   97.94%\n",
            "   Early Stopping Triggered.\n",
            "\n",
            "Training Complete.\n",
            "STARTING TRAINING PIPELINE: SimpleCNN_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run u0zk4e9q\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_173416-u0zk4e9q\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run celestial-fog-3\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/u0zk4e9q\n",
            "Training on cuda using model: simple_cnn\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "BASELINE MODE: Using only Real data.\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:08<00:00,  5.57it/s]\n",
            "   Train Loss: 0.3942 | Train Acc: 83.73%\n",
            "   Val Loss:   0.2756 | Val Acc:   90.27%\n",
            "   Validation Accuracy improved (0.00% -> 90.27%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.35it/s]\n",
            "   Train Loss: 0.2736 | Train Acc: 89.25%\n",
            "   Val Loss:   0.2488 | Val Acc:   91.25%\n",
            "   Validation Accuracy improved (90.27% -> 91.25%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.51it/s]\n",
            "   Train Loss: 0.2624 | Train Acc: 89.62%\n",
            "   Val Loss:   0.2586 | Val Acc:   90.44%\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.43it/s]\n",
            "   Train Loss: 0.2519 | Train Acc: 89.98%\n",
            "   Val Loss:   0.2322 | Val Acc:   91.46%\n",
            "   Validation Accuracy improved (91.25% -> 91.46%). Saving model...\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "   Train Loss: 0.2403 | Train Acc: 90.58%\n",
            "   Val Loss:   0.2281 | Val Acc:   91.73%\n",
            "   Validation Accuracy improved (91.46% -> 91.73%). Saving model...\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.53it/s]\n",
            "   Train Loss: 0.2372 | Train Acc: 90.51%\n",
            "   Val Loss:   0.2152 | Val Acc:   91.76%\n",
            "   Validation Accuracy improved (91.73% -> 91.76%). Saving model...\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.24it/s]\n",
            "   Train Loss: 0.2238 | Train Acc: 90.84%\n",
            "   Val Loss:   0.2097 | Val Acc:   92.13%\n",
            "   Validation Accuracy improved (91.76% -> 92.13%). Saving model...\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.49it/s]\n",
            "   Train Loss: 0.2173 | Train Acc: 91.47%\n",
            "   Val Loss:   0.1995 | Val Acc:   92.40%\n",
            "   Validation Accuracy improved (92.13% -> 92.40%). Saving model...\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.36it/s]\n",
            "   Train Loss: 0.2121 | Train Acc: 91.83%\n",
            "   Val Loss:   0.2035 | Val Acc:   91.89%\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.53it/s]\n",
            "   Train Loss: 0.2141 | Train Acc: 91.40%\n",
            "   Val Loss:   0.1923 | Val Acc:   92.46%\n",
            "   Validation Accuracy improved (92.40% -> 92.46%). Saving model...\n",
            "\n",
            "Epoch 11/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.33it/s]\n",
            "   Train Loss: 0.2023 | Train Acc: 91.90%\n",
            "   Val Loss:   0.1934 | Val Acc:   93.05%\n",
            "   Validation Accuracy improved (92.46% -> 93.05%). Saving model...\n",
            "\n",
            "Epoch 12/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "   Train Loss: 0.2025 | Train Acc: 91.90%\n",
            "   Val Loss:   0.1927 | Val Acc:   92.17%\n",
            "\n",
            "Epoch 13/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.49it/s]\n",
            "   Train Loss: 0.1951 | Train Acc: 92.36%\n",
            "   Val Loss:   0.1914 | Val Acc:   92.19%\n",
            "\n",
            "Epoch 14/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.54it/s]\n",
            "   Train Loss: 0.1988 | Train Acc: 92.03%\n",
            "   Val Loss:   0.1799 | Val Acc:   93.08%\n",
            "   Validation Accuracy improved (93.05% -> 93.08%). Saving model...\n",
            "\n",
            "Epoch 15/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "   Train Loss: 0.1963 | Train Acc: 92.33%\n",
            "   Val Loss:   0.1784 | Val Acc:   93.03%\n",
            "\n",
            "Epoch 16/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.36it/s]\n",
            "   Train Loss: 0.1810 | Train Acc: 93.06%\n",
            "   Val Loss:   0.1827 | Val Acc:   93.27%\n",
            "   Validation Accuracy improved (93.08% -> 93.27%). Saving model...\n",
            "\n",
            "Epoch 17/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.42it/s]\n",
            "   Train Loss: 0.1849 | Train Acc: 92.66%\n",
            "   Val Loss:   0.1824 | Val Acc:   93.33%\n",
            "   Validation Accuracy improved (93.27% -> 93.33%). Saving model...\n",
            "\n",
            "Epoch 18/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.51it/s]\n",
            "   Train Loss: 0.1797 | Train Acc: 93.02%\n",
            "   Val Loss:   0.1793 | Val Acc:   93.57%\n",
            "   Validation Accuracy improved (93.33% -> 93.57%). Saving model...\n",
            "\n",
            "Epoch 19/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.44it/s]\n",
            "   Train Loss: 0.1833 | Train Acc: 92.39%\n",
            "   Val Loss:   0.1716 | Val Acc:   93.62%\n",
            "   Validation Accuracy improved (93.57% -> 93.62%). Saving model...\n",
            "\n",
            "Epoch 20/20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "wandb: updating run metadata\n",
            "wandb: uploading best_model.pth; uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading best_model.pth; uploading config.yaml\n",
            "wandb: uploading best_model.pth\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "wandb:   val_loss ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 20\n",
            "wandb:  train_acc 92.75794\n",
            "wandb: train_loss 0.17306\n",
            "wandb:    val_acc 93.63492\n",
            "wandb:   val_loss 0.16866\n",
            "wandb: \n",
            "wandb: üöÄ View run celestial-fog-3 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/u0zk4e9q\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_173416-u0zk4e9q/logs\n",
            "   Train Loss: 0.1731 | Train Acc: 92.76%\n",
            "   Val Loss:   0.1687 | Val Acc:   93.63%\n",
            "   Validation Accuracy improved (93.62% -> 93.63%). Saving model...\n",
            "\n",
            "Training Complete.\n",
            "STARTING TRAINING PIPELINE: SimpleCNN_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run hsfj7rdq\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_174157-hsfj7rdq\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run northern-dawn-4\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/hsfj7rdq\n",
            "Training on cuda using model: simple_cnn\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "AUGMENTATION ON: Injecting synthetic data...\n",
            "   -> Found 2000 synthetic wildfire images.\n",
            "   -> Merged Dataset Size: 5024\n",
            "   -> Synthetic Influence: 39.81% of training data\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 1/20:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 55/79 [00:10<00:04,  5.41it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:14<00:00,  5.56it/s]\n",
            "   Train Loss: 0.3439 | Train Acc: 86.45%\n",
            "   Val Loss:   0.2709 | Val Acc:   90.63%\n",
            "   Validation Accuracy improved (0.00% -> 90.63%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 2/20:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:10<00:02,  6.01it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.19it/s]\n",
            "   Train Loss: 0.2350 | Train Acc: 91.58%\n",
            "   Val Loss:   0.2421 | Val Acc:   91.21%\n",
            "   Validation Accuracy improved (90.63% -> 91.21%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 3/20:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:10<00:02,  6.00it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.14it/s]\n",
            "   Train Loss: 0.2064 | Train Acc: 92.58%\n",
            "   Val Loss:   0.2280 | Val Acc:   91.40%\n",
            "   Validation Accuracy improved (91.21% -> 91.40%). Saving model...\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 4/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.34it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.41it/s]\n",
            "   Train Loss: 0.1972 | Train Acc: 92.87%\n",
            "   Val Loss:   0.2468 | Val Acc:   89.92%\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 5/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:10<00:02,  6.26it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.37it/s]\n",
            "   Train Loss: 0.1719 | Train Acc: 93.87%\n",
            "   Val Loss:   0.2077 | Val Acc:   92.08%\n",
            "   Validation Accuracy improved (91.40% -> 92.08%). Saving model...\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 6/20:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/79 [00:10<00:03,  5.95it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  6.07it/s]\n",
            "   Train Loss: 0.1661 | Train Acc: 94.15%\n",
            "   Val Loss:   0.2033 | Val Acc:   92.25%\n",
            "   Validation Accuracy improved (92.08% -> 92.25%). Saving model...\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 7/20:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/79 [00:10<00:03,  5.96it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.12it/s]\n",
            "   Train Loss: 0.1593 | Train Acc: 94.65%\n",
            "   Val Loss:   0.2009 | Val Acc:   92.27%\n",
            "   Validation Accuracy improved (92.25% -> 92.27%). Saving model...\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 8/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:10<00:02,  6.25it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.38it/s]\n",
            "   Train Loss: 0.1586 | Train Acc: 94.53%\n",
            "   Val Loss:   0.2037 | Val Acc:   92.27%\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 9/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.38it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.44it/s]\n",
            "   Train Loss: 0.1521 | Train Acc: 94.67%\n",
            "   Val Loss:   0.1937 | Val Acc:   92.75%\n",
            "   Validation Accuracy improved (92.27% -> 92.75%). Saving model...\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 10/20:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:10<00:02,  6.01it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.17it/s]\n",
            "   Train Loss: 0.1495 | Train Acc: 94.73%\n",
            "   Val Loss:   0.1988 | Val Acc:   92.46%\n",
            "\n",
            "Epoch 11/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 11/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.26it/s]\n",
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.32it/s]\n",
            "   Train Loss: 0.1467 | Train Acc: 94.80%\n",
            "   Val Loss:   0.1993 | Val Acc:   92.30%\n",
            "\n",
            "Epoch 12/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 12/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.35it/s]\n",
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.43it/s]\n",
            "   Train Loss: 0.1445 | Train Acc: 94.98%\n",
            "   Val Loss:   0.2029 | Val Acc:   92.08%\n",
            "\n",
            "Epoch 13/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 13/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.35it/s]\n",
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.42it/s]\n",
            "   Train Loss: 0.1377 | Train Acc: 95.12%\n",
            "   Val Loss:   0.1907 | Val Acc:   92.71%\n",
            "\n",
            "Epoch 14/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 14/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.36it/s]\n",
            "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.43it/s]\n",
            "   Train Loss: 0.1363 | Train Acc: 95.28%\n",
            "   Val Loss:   0.1900 | Val Acc:   92.78%\n",
            "   Validation Accuracy improved (92.75% -> 92.78%). Saving model...\n",
            "\n",
            "Epoch 15/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 15/20:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 60/79 [00:10<00:03,  5.98it/s]\n",
            "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.12it/s]\n",
            "   Train Loss: 0.1316 | Train Acc: 95.36%\n",
            "   Val Loss:   0.2002 | Val Acc:   92.33%\n",
            "\n",
            "Epoch 16/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 16/20:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62/79 [00:10<00:02,  6.17it/s]\n",
            "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.26it/s]\n",
            "   Train Loss: 0.1312 | Train Acc: 95.46%\n",
            "   Val Loss:   0.1855 | Val Acc:   92.94%\n",
            "   Validation Accuracy improved (92.78% -> 92.94%). Saving model...\n",
            "\n",
            "Epoch 17/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 17/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.34it/s]\n",
            "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.41it/s]\n",
            "   Train Loss: 0.1276 | Train Acc: 95.62%\n",
            "   Val Loss:   0.2039 | Val Acc:   92.19%\n",
            "\n",
            "Epoch 18/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 18/20:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 61/79 [00:10<00:02,  6.08it/s]\n",
            "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.22it/s]\n",
            "   Train Loss: 0.1317 | Train Acc: 95.46%\n",
            "   Val Loss:   0.1825 | Val Acc:   93.37%\n",
            "   Validation Accuracy improved (92.94% -> 93.37%). Saving model...\n",
            "\n",
            "Epoch 19/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 19/20:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 64/79 [00:10<00:02,  6.34it/s]\n",
            "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.40it/s]\n",
            "   Train Loss: 0.1258 | Train Acc: 95.54%\n",
            "   Val Loss:   0.1856 | Val Acc:   92.81%\n",
            "\n",
            "Epoch 20/20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 20/20:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:10<00:02,  6.17it/s]\n",
            "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:12<00:00,  6.28it/s]\n",
            "wandb: uploading best_model.pth; updating run metadata\n",
            "wandb: uploading best_model.pth; uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading best_model.pth\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñá‚ñà\n",
            "wandb:   val_loss ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 20\n",
            "wandb:  train_acc 95.76035\n",
            "wandb: train_loss 0.12554\n",
            "wandb:    val_acc 93.39683\n",
            "wandb:   val_loss 0.17748\n",
            "wandb: \n",
            "wandb: üöÄ View run northern-dawn-4 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/hsfj7rdq\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_174157-hsfj7rdq/logs\n",
            "   Train Loss: 0.1255 | Train Acc: 95.76%\n",
            "   Val Loss:   0.1775 | Val Acc:   93.40%\n",
            "   Validation Accuracy improved (93.37% -> 93.40%). Saving model...\n",
            "\n",
            "Training Complete.\n",
            "STARTING TRAINING PIPELINE: EfficientNet_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run 61fxiygm\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_175116-61fxiygm\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run polar-armadillo-5\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/61fxiygm\n",
            "Training on cuda using model: efficientnet\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "BASELINE MODE: Using only Real data.\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "\n",
            "  0%|          | 0.00/20.5M [00:00<?, ?B/s]\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 16.0M/20.5M [00:00<00:00, 166MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 161MB/s]\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 1/20:   1%|          | 1/95 [00:14<21:58, 14.03s/it]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:34<00:00,  3.11it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:34<00:00,  2.74it/s]\n",
            "   Train Loss: 0.2641 | Train Acc: 90.31%\n",
            "   Val Loss:   0.1170 | Val Acc:   96.49%\n",
            "   Validation Accuracy improved (0.00% -> 96.49%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.05it/s]\n",
            "   Train Loss: 0.1115 | Train Acc: 95.93%\n",
            "   Val Loss:   0.0800 | Val Acc:   97.63%\n",
            "   Validation Accuracy improved (96.49% -> 97.63%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.09it/s]\n",
            "   Train Loss: 0.0794 | Train Acc: 97.12%\n",
            "   Val Loss:   0.0681 | Val Acc:   97.83%\n",
            "   Validation Accuracy improved (97.63% -> 97.83%). Saving model...\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.13it/s]\n",
            "   Train Loss: 0.0623 | Train Acc: 97.65%\n",
            "   Val Loss:   0.0597 | Val Acc:   98.05%\n",
            "   Validation Accuracy improved (97.83% -> 98.05%). Saving model...\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.13it/s]\n",
            "   Train Loss: 0.0404 | Train Acc: 98.51%\n",
            "   Val Loss:   0.0617 | Val Acc:   98.11%\n",
            "   Validation Accuracy improved (98.05% -> 98.11%). Saving model...\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.10it/s]\n",
            "   Train Loss: 0.0330 | Train Acc: 98.88%\n",
            "   Val Loss:   0.0585 | Val Acc:   98.19%\n",
            "   Validation Accuracy improved (98.11% -> 98.19%). Saving model...\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.09it/s]\n",
            "   Train Loss: 0.0227 | Train Acc: 99.27%\n",
            "   Val Loss:   0.0517 | Val Acc:   98.41%\n",
            "   Validation Accuracy improved (98.19% -> 98.41%). Saving model...\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.10it/s]\n",
            "   Train Loss: 0.0196 | Train Acc: 99.27%\n",
            "   Val Loss:   0.0535 | Val Acc:   98.46%\n",
            "   Validation Accuracy improved (98.41% -> 98.46%). Saving model...\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.11it/s]\n",
            "   Train Loss: 0.0151 | Train Acc: 99.57%\n",
            "   Val Loss:   0.0613 | Val Acc:   98.25%\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.09it/s]\n",
            "   Train Loss: 0.0094 | Train Acc: 99.87%\n",
            "   Val Loss:   0.0631 | Val Acc:   98.41%\n",
            "\n",
            "Epoch 11/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.12it/s]\n",
            "   Train Loss: 0.0120 | Train Acc: 99.60%\n",
            "   Val Loss:   0.0581 | Val Acc:   98.21%\n",
            "\n",
            "Epoch 12/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.14it/s]\n",
            "   Train Loss: 0.0067 | Train Acc: 99.80%\n",
            "   Val Loss:   0.0645 | Val Acc:   98.30%\n",
            "\n",
            "Epoch 13/20:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.14it/s]\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 12-12, summary, console lines 53-55\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá\n",
            "wandb:   val_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 13\n",
            "wandb:  train_acc 99.76852\n",
            "wandb: train_loss 0.00762\n",
            "wandb:    val_acc 98.22222\n",
            "wandb:   val_loss 0.06452\n",
            "wandb: \n",
            "wandb: üöÄ View run polar-armadillo-5 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/61fxiygm\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_175116-61fxiygm/logs\n",
            "   Train Loss: 0.0076 | Train Acc: 99.77%\n",
            "   Val Loss:   0.0645 | Val Acc:   98.22%\n",
            "   Early Stopping Triggered.\n",
            "\n",
            "Training Complete.\n",
            "STARTING TRAINING PIPELINE: EfficientNet_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run uq9yv108\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251202_175655-uq9yv108\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run morning-sky-6\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/uq9yv108\n",
            "Training on cuda using model: efficientnet\n",
            "SCARCITY MODE ENABLED: Using 10.0% of Real Data.\n",
            "   Original Size: 30249 -> Reduced Size: 3024\n",
            "Real Data Ready. Size: 3024\n",
            "AUGMENTATION ON: Injecting synthetic data...\n",
            "   -> Found 2000 synthetic wildfire images.\n",
            "   -> Merged Dataset Size: 5024\n",
            "   -> Synthetic Influence: 39.81% of training data\n",
            "Starting Training Loop...\n",
            "\n",
            "Epoch 1/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 1/20:   1%|          | 1/157 [00:13<35:47, 13.77s/it]\n",
            "Epoch 1/20:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 116/157 [00:23<00:06,  5.87it/s]\n",
            "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:27<00:00,  5.72it/s]\n",
            "   Train Loss: 0.2101 | Train Acc: 92.71%\n",
            "   Val Loss:   0.0986 | Val Acc:   96.90%\n",
            "   Validation Accuracy improved (0.00% -> 96.90%). Saving model...\n",
            "\n",
            "Epoch 2/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 2/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 111/157 [00:10<00:04, 11.08it/s]\n",
            "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.14it/s]\n",
            "   Train Loss: 0.0745 | Train Acc: 97.69%\n",
            "   Val Loss:   0.0784 | Val Acc:   97.35%\n",
            "   Validation Accuracy improved (96.90% -> 97.35%). Saving model...\n",
            "\n",
            "Epoch 3/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 3/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0542 | Train Acc: 98.23%\n",
            "   Val Loss:   0.0769 | Val Acc:   97.52%\n",
            "   Validation Accuracy improved (97.35% -> 97.52%). Saving model...\n",
            "\n",
            "Epoch 4/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 4/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.16it/s]\n",
            "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.21it/s]\n",
            "   Train Loss: 0.0345 | Train Acc: 98.93%\n",
            "   Val Loss:   0.0659 | Val Acc:   97.71%\n",
            "   Validation Accuracy improved (97.52% -> 97.71%). Saving model...\n",
            "\n",
            "Epoch 5/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 5/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "   Train Loss: 0.0220 | Train Acc: 99.36%\n",
            "   Val Loss:   0.0653 | Val Acc:   97.87%\n",
            "   Validation Accuracy improved (97.71% -> 97.87%). Saving model...\n",
            "\n",
            "Epoch 6/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 6/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0220 | Train Acc: 99.34%\n",
            "   Val Loss:   0.0717 | Val Acc:   97.71%\n",
            "\n",
            "Epoch 7/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 7/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "   Train Loss: 0.0194 | Train Acc: 99.34%\n",
            "   Val Loss:   0.0709 | Val Acc:   97.57%\n",
            "\n",
            "Epoch 8/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 8/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.18it/s]\n",
            "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "   Train Loss: 0.0109 | Train Acc: 99.64%\n",
            "   Val Loss:   0.0625 | Val Acc:   98.13%\n",
            "   Validation Accuracy improved (97.87% -> 98.13%). Saving model...\n",
            "\n",
            "Epoch 9/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 9/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0110 | Train Acc: 99.66%\n",
            "   Val Loss:   0.0743 | Val Acc:   97.86%\n",
            "\n",
            "Epoch 10/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 10/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.16it/s]\n",
            "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.21it/s]\n",
            "   Train Loss: 0.0108 | Train Acc: 99.72%\n",
            "   Val Loss:   0.0678 | Val Acc:   97.97%\n",
            "\n",
            "Epoch 11/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 11/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.19it/s]\n",
            "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.23it/s]\n",
            "   Train Loss: 0.0119 | Train Acc: 99.60%\n",
            "   Val Loss:   0.0725 | Val Acc:   97.70%\n",
            "\n",
            "Epoch 12/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 12/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.21it/s]\n",
            "   Train Loss: 0.0073 | Train Acc: 99.80%\n",
            "   Val Loss:   0.0664 | Val Acc:   98.24%\n",
            "   Validation Accuracy improved (98.13% -> 98.24%). Saving model...\n",
            "\n",
            "Epoch 13/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 13/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.13it/s]\n",
            "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.18it/s]\n",
            "   Train Loss: 0.0118 | Train Acc: 99.74%\n",
            "   Val Loss:   0.0677 | Val Acc:   98.14%\n",
            "\n",
            "Epoch 14/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 14/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0065 | Train Acc: 99.82%\n",
            "   Val Loss:   0.0852 | Val Acc:   97.67%\n",
            "\n",
            "Epoch 15/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 15/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "   Train Loss: 0.0052 | Train Acc: 99.84%\n",
            "   Val Loss:   0.0634 | Val Acc:   98.25%\n",
            "   Validation Accuracy improved (98.24% -> 98.25%). Saving model...\n",
            "\n",
            "Epoch 16/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 16/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.16it/s]\n",
            "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0043 | Train Acc: 99.86%\n",
            "   Val Loss:   0.0700 | Val Acc:   98.24%\n",
            "\n",
            "Epoch 17/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 17/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "   Train Loss: 0.0098 | Train Acc: 99.76%\n",
            "   Val Loss:   0.0709 | Val Acc:   97.94%\n",
            "\n",
            "Epoch 18/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 18/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "   Train Loss: 0.0064 | Train Acc: 99.84%\n",
            "   Val Loss:   0.0727 | Val Acc:   97.83%\n",
            "\n",
            "Epoch 19/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 19/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.19it/s]\n",
            "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.23it/s]\n",
            "   Train Loss: 0.0082 | Train Acc: 99.66%\n",
            "   Val Loss:   0.0993 | Val Acc:   97.84%\n",
            "\n",
            "Epoch 20/20:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 20/20:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.17it/s]\n",
            "Epoch 20/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.22it/s]\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading history steps 19-19, summary, console lines 74-77\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:      epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb:  train_acc ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "wandb: train_loss ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "wandb:    val_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñá‚ñÖ‚ñà‚ñá‚ñÖ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ\n",
            "wandb:   val_loss ‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÇ\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:      epoch 20\n",
            "wandb:  train_acc 99.62182\n",
            "wandb: train_loss 0.01167\n",
            "wandb:    val_acc 97.88889\n",
            "wandb:   val_loss 0.06892\n",
            "wandb: \n",
            "wandb: üöÄ View run morning-sky-6 at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/uq9yv108\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251202_175655-uq9yv108/logs\n",
            "   Train Loss: 0.0117 | Train Acc: 99.62%\n",
            "   Val Loss:   0.0689 | Val Acc:   97.89%\n",
            "   Early Stopping Triggered.\n",
            "\n",
            "Training Complete.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from IPython.display import display, Image\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "api = wandb.Api()\n",
        "CURRENT_ENTITY = api.default_entity\n",
        "PROJECT = \"wildfire-final-benchmark\"\n",
        "DRIVE_SAVE_ROOT = \"/content/drive/MyDrive/Wildfire_Project/saved_models\"\n",
        "\n",
        "TARGET_CONFIGS = [\n",
        "    (\"resnet50\", False, 0.5), (\"resnet50\", True, 0.5),\n",
        "    (\"simple_cnn\", False, 0.5), (\"simple_cnn\", True, 0.5),\n",
        "    (\"efficientnet\", False, 0.2), (\"efficientnet\", True, 0.2),\n",
        "]\n",
        "\n",
        "def force_cleanup():\n",
        "    # Remove any potential conflict files\n",
        "    if os.path.exists(\"best_model.pth\"): os.remove(\"best_model.pth\")\n",
        "    if os.path.exists(\"confusion_matrix.png\"): os.remove(\"confusion_matrix.png\")\n",
        "    for f in glob.glob(\"weights_*.pth\"): os.remove(f)\n",
        "\n",
        "def run_test_pipeline(model_arch, use_synthetic, dropout_val):\n",
        "    label = f\"{model_arch}_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"PROCESSING: {label}\")\n",
        "\n",
        "    force_cleanup()\n",
        "\n",
        "    path = f\"{CURRENT_ENTITY}/{PROJECT}\"\n",
        "    try:\n",
        "        runs = api.runs(path)\n",
        "    except Exception as e:\n",
        "        print(f\"WandB Connection Error: {e}\")\n",
        "        return\n",
        "\n",
        "    target_run = None\n",
        "    for run in runs:\n",
        "        try:\n",
        "            cfg = run.config\n",
        "            if cfg.get('model', {}).get('name') != model_arch: continue\n",
        "            run_syn = cfg.get('dataset', {}).get('params', {}).get('use_synthetic')\n",
        "            if str(run_syn).lower() != str(use_synthetic).lower(): continue\n",
        "            target_run = run\n",
        "            break\n",
        "        except: continue\n",
        "\n",
        "    if not target_run:\n",
        "        print(f\"Run not found: {label}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found Run ID: {target_run.id}\")\n",
        "\n",
        "    # Define a UNIQUE filename for this specific test\n",
        "    unique_filename = f\"weights_{label}.pth\"\n",
        "\n",
        "    # Try Drive First\n",
        "    drive_folder_name = f\"{model_arch}_{target_run.id}\"\n",
        "    drive_file_path = os.path.join(DRIVE_SAVE_ROOT, drive_folder_name, \"best_weights.pth\")\n",
        "\n",
        "    if os.path.exists(drive_file_path):\n",
        "        print(f\"Copying from Drive: {drive_file_path}\")\n",
        "        shutil.copy(drive_file_path, unique_filename)\n",
        "    else:\n",
        "        print(\"File missing on Drive. Attempting WandB download...\")\n",
        "        try:\n",
        "            target_run.file(\"best_model.pth\").download(replace=True, root=\".\")\n",
        "            os.rename(\"best_model.pth\", unique_filename)\n",
        "        except:\n",
        "            print(\"Download Failed.\")\n",
        "            return\n",
        "\n",
        "    # Execute Test with the unique filename\n",
        "    cmd = [\n",
        "        \"python\", \"test.py\",\n",
        "        f\"model.name={model_arch}\",\n",
        "        f\"model.dropout={dropout_val}\",\n",
        "        f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "        \"training.batch_size=32\",\n",
        "        \"wandb.mode=disabled\",\n",
        "        f\"+model_path={unique_filename}\"\n",
        "    ]\n",
        "\n",
        "    proc = subprocess.run(\n",
        "        cmd,\n",
        "        cwd=\"/content/WildfireDetectionDL\",\n",
        "        capture_output=True,\n",
        "        text=True\n",
        "    )\n",
        "\n",
        "    if proc.returncode == 0:\n",
        "        print(\"SUCCESS:\")\n",
        "        for line in proc.stdout.split('\\n'):\n",
        "            if any(k in line for k in [\"Accuracy:\", \"Precision:\", \"Recall:\", \"F1-Score:\"]):\n",
        "                print(f\"   {line.strip()}\")\n",
        "\n",
        "        if os.path.exists(\"confusion_matrix.png\"):\n",
        "            display(Image(\"confusion_matrix.png\"))\n",
        "    else:\n",
        "        print(\"FAILED:\")\n",
        "        lines = proc.stderr.split('\\n')\n",
        "        for line in lines:\n",
        "            if \"Error\" in line or \"Traceback\" in line:\n",
        "                print(line)\n",
        "\n",
        "    # Delete the unique file to save space\n",
        "    if os.path.exists(unique_filename):\n",
        "        os.remove(unique_filename)\n",
        "\n",
        "print(f\"Project: {CURRENT_ENTITY}/{PROJECT}\")\n",
        "for arch, syn, drop in TARGET_CONFIGS:\n",
        "    run_test_pipeline(arch, syn, drop)"
      ],
      "metadata": {
        "id": "XzT7nl5MA7cO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89c4ea9d-4389-4672-8cd4-d3eb1f65af36"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project: pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "\n",
            "========================================\n",
            "PROCESSING: resnet50_RealOnly\n",
            "Found Run ID: zlhelkcq\n",
            "Looking in Drive: /content/drive/MyDrive/Wildfire_Project/saved_models/resnet50_zlhelkcq/best_weights.pth\n",
            "Weights successfully copied from Drive.\n",
            "FAILED:\n",
            "Error executing job with overrides: ['model.name=resnet50', 'model.dropout=0.5', 'dataset.params.use_synthetic=false', 'training.batch_size=32', 'wandb.mode=disabled']\n",
            "Traceback (most recent call last):\n",
            "    raise RuntimeError(\"Architecture Mismatch: File contains SimpleCNN weights, but Model is ResNet.\")\n",
            "RuntimeError: Architecture Mismatch: File contains SimpleCNN weights, but Model is ResNet.\n",
            "\n",
            "========================================\n",
            "PROCESSING: resnet50_Synthetic\n",
            "Found Run ID: xlz83yql\n",
            "Looking in Drive: /content/drive/MyDrive/Wildfire_Project/saved_models/resnet50_xlz83yql/best_weights.pth\n",
            "Weights successfully copied from Drive.\n",
            "FAILED:\n",
            "Error executing job with overrides: ['model.name=resnet50', 'model.dropout=0.5', 'dataset.params.use_synthetic=true', 'training.batch_size=32', 'wandb.mode=disabled']\n",
            "Traceback (most recent call last):\n",
            "    raise RuntimeError(\"Architecture Mismatch: File contains SimpleCNN weights, but Model is ResNet.\")\n",
            "RuntimeError: Architecture Mismatch: File contains SimpleCNN weights, but Model is ResNet.\n",
            "\n",
            "========================================\n",
            "PROCESSING: simple_cnn_RealOnly\n",
            "Found Run ID: u0zk4e9q\n",
            "Looking in Drive: /content/drive/MyDrive/Wildfire_Project/saved_models/simple_cnn_u0zk4e9q/best_weights.pth\n",
            "Weights successfully copied from Drive.\n",
            "SUCCESS:\n",
            "   Accuracy:  0.4448\n",
            "   Precision: 0.2000\n",
            "   Recall:    0.0017\n",
            "   F1-Score:  0.0034\n",
            "\n",
            "========================================\n",
            "PROCESSING: simple_cnn_Synthetic\n",
            "Found Run ID: hsfj7rdq\n",
            "Looking in Drive: /content/drive/MyDrive/Wildfire_Project/saved_models/simple_cnn_hsfj7rdq/best_weights.pth\n",
            "Weights successfully copied from Drive.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4150175563.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Project: {CURRENT_ENTITY}/{PROJECT}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTARGET_CONFIGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mrun_test_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4150175563.py\u001b[0m in \u001b[0;36mrun_test_pipeline\u001b[0;34m(model_arch, use_synthetic, dropout_val)\u001b[0m\n\u001b[1;32m    100\u001b[0m     ]\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     proc = subprocess.run(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mcwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/WildfireDetectionDL\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}