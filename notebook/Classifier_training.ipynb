{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoPozio/WildfireDetectionDL/blob/main/notebook/Classifier_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NicoPozio/WildfireDetectionDL.git"
      ],
      "metadata": {
        "id": "NUhUF7tDYgzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce3548e-d84f-4cbe-a722-4160758d5424"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WildfireDetectionDL'...\n",
            "remote: Enumerating objects: 318, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 318 (delta 70), reused 2 (delta 0), pack-reused 188 (from 1)\u001b[K\n",
            "Receiving objects: 100% (318/318), 317.30 KiB | 10.24 MiB/s, done.\n",
            "Resolving deltas: 100% (165/165), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "repo_path = '/content/WildfireDetectionDL'\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.append(repo_path)"
      ],
      "metadata": {
        "id": "F1sXhKEnf1dO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: Update Code\n",
        "import os\n",
        "\n",
        "REPO_PATH = \"/content/WildfireDetectionDL\"\n",
        "\n",
        "print(\"Syncing with GitHub...\")\n",
        "!cd {REPO_PATH} && git pull\n",
        "\n",
        "print(\"Code updated. You can now run the Sweep or Train cell immediately.\")"
      ],
      "metadata": {
        "id": "hpvQdBgJvSDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93a57c2-6746-47fe-e0a0-4e10e4d1a0b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Syncing with GitHub...\n",
            "Already up to date.\n",
            "Code updated. You can now run the Sweep or Train cell immediately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Project Dependencies\n",
        "#hydra-core: Configuration management\n",
        "#wandb: Experiment tracking\n",
        "#omegaconf: Dict handling for Hydra\n",
        "!pip install -q hydra-core wandb omegaconf\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive Mounted\")\n"
      ],
      "metadata": {
        "id": "xYMO3qvxQo_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40e3485-add0-4fee-fee1-ab12c78c14f0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/154.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Google Drive Mounted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "try:\n",
        "    #Fetch key from Colab Secrets\n",
        "    api_key = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "    #Set as Environment Variable\n",
        "    #This ensures Hydra and subprocesses can find it automatically\n",
        "    os.environ[\"WANDB_API_KEY\"] = api_key\n",
        "\n",
        "    wandb.login()\n",
        "    print(\"Logged in to WandB\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Authentication Failed: {e}\")\n",
        "    print(\"Action Required: Go to the 'Secrets' tab (Key icon) on the left.\")\n",
        "    print(\"Add a new secret named 'WANDB_API_KEY' with your key from https://wandb.ai/authorize\")"
      ],
      "metadata": {
        "id": "HRabcBKtQqgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5cee2dc-540a-4dc8-930b-e537807b26bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpozioniccolo\u001b[0m (\u001b[33mpozioniccolo-sapienza-universit-di-roma\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in to WandB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we download the dataset, we check if the user has the data in its google drive, if not it's downloaded from a public link"
      ],
      "metadata": {
        "id": "Ti3-Olu9Xnqp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "509SQeSJXm1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a580ee6-550d-44d0-a354-9cfd30d5d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42860/42860 [00:13<00:00, 3225.75files/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Extracting synthetic_wildfire_2k.zip to /content/data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2003/2003 [00:01<00:00, 1327.73files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> Success: Extracted to /content/data\n",
            "Data Ready\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import gdown\n",
        "from src.utils import extract_zip\n",
        "\n",
        "#Destination on Colab\n",
        "local_root = \"/content/data\"\n",
        "os.makedirs(local_root, exist_ok=True)\n",
        "!rm -rf {local_root}/*\n",
        "\n",
        "#Paths on drive (in case the CyclaGAN notebook is exectued)\n",
        "drive_dataset_path = \"/content/drive/MyDrive/Wildfire_Project/dataset.zip\"\n",
        "drive_synthetic_path = \"/content/drive/MyDrive/Wildfire_Project/synthetic_wildfire_2k.zip\"\n",
        "\n",
        "#Paths on Colab\n",
        "target_dataset_zip = os.path.join(local_root, \"dataset.zip\")\n",
        "target_synthetic_zip = os.path.join(local_root, \"synthetic_wildfire_2k.zip\")\n",
        "\n",
        "\n",
        "\n",
        "#Check if the file are present\n",
        "if os.path.isfile(drive_dataset_path) and os.path.isfile(drive_synthetic_path):\n",
        "    !cp \"{drive_dataset_path}\" \"{target_dataset_zip}\"\n",
        "    !cp \"{drive_synthetic_path}\" \"{target_synthetic_zip}\"\n",
        "\n",
        "else:\n",
        "\n",
        "    DATASET_ID = \"17KPBVodZkmBYqz7252mDk6hfY55eMU-Q\"\n",
        "    SYNTHETIC_ID = \"1KyI09FDCAkLp1BYO-VgD7zRMrtrl3anK\"\n",
        "\n",
        "    gdown.download(id=DATASET_ID, output=target_dataset_zip, quiet=False)\n",
        "\n",
        "    gdown.download(id=SYNTHETIC_ID, output=target_synthetic_zip, quiet=False)\n",
        "\n",
        "\n",
        "if os.path.exists(target_dataset_zip) and os.path.exists(target_synthetic_zip):\n",
        "    if os.path.getsize(target_dataset_zip) > 0:\n",
        "        extract_zip(target_dataset_zip, local_root)\n",
        "    if os.path.getsize(target_synthetic_zip) > 0:\n",
        "        extract_zip(target_synthetic_zip, local_root)\n",
        "    print(\"Data Ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define your data root\n",
        "DATA_ROOT = \"/content/data\"\n",
        "\n",
        "print(f\"Scanning {DATA_ROOT} for corrupt images...\")\n",
        "\n",
        "corrupt_count = 0\n",
        "for root, dirs, files in os.walk(DATA_ROOT):\n",
        "    for filename in files:\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            file_path = os.path.join(root, filename)\n",
        "            try:\n",
        "                # Try to fully load the image bytes\n",
        "                with Image.open(file_path) as img:\n",
        "                    img.load()\n",
        "            except OSError:\n",
        "                print(f\"Found corrupt image: {file_path}\")\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                    print(f\"Deleted {filename}\")\n",
        "                    corrupt_count += 1\n",
        "                except:\n",
        "                    print(f\"Could not delete {filename}\")\n",
        "\n",
        "print(f\"\\nScan Complete. Removed {corrupt_count} corrupt files.\")"
      ],
      "metadata": {
        "id": "pNVIFW9gqYb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f85ac2-4610-43de-d218-7b162a950322"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning /content/data for corrupt images...\n",
            "Found corrupt image: /content/data/dataset/test/wildfire/-73.15884,46.38819.jpg\n",
            "Deleted -73.15884,46.38819.jpg\n",
            "Found corrupt image: /content/data/dataset/train/nowildfire/-114.152378,51.027198.jpg\n",
            "Deleted -114.152378,51.027198.jpg\n",
            "\n",
            "Scan Complete. Removed 2 corrupt files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "# 1. Define Paths Constants\n",
        "REPO_ROOT = \"/content/WildfireDetectionDL\"\n",
        "SWEEP_CONFIG_PATH = os.path.join(REPO_ROOT, \"conf\", \"sweep.yaml\")\n",
        "\n",
        "# 2. Validation\n",
        "if not os.path.exists(SWEEP_CONFIG_PATH):\n",
        "    print(f\"CRITICAL ERROR: Could not find sweep.yaml at {SWEEP_CONFIG_PATH}\")\n",
        "else:\n",
        "    print(f\"Registering Sweep from {SWEEP_CONFIG_PATH}\")\n",
        "\n",
        "    # 3. Register the sweep\n",
        "    result = subprocess.run(\n",
        "        [\"wandb\", \"sweep\", SWEEP_CONFIG_PATH],\n",
        "        capture_output=True,\n",
        "        text=True,\n",
        "        # CORRECTION: cwd must be the directory, not the file\n",
        "        cwd=REPO_ROOT\n",
        "    )\n",
        "\n",
        "    output_text = result.stderr + result.stdout\n",
        "    print(\"Raw Output:\", output_text)\n",
        "\n",
        "    # 4. Extract Sweep ID\n",
        "    sweep_id = None\n",
        "    for line in output_text.split('\\n'):\n",
        "        if \"wandb agent\" in line:\n",
        "            parts = line.strip().split(\"wandb agent \")\n",
        "            if len(parts) > 1:\n",
        "                sweep_id = parts[-1].strip()\n",
        "                break\n",
        "\n",
        "    # 5. Launch the Agent\n",
        "    if sweep_id:\n",
        "        print(f\"\\nSUCCESS: Detected Sweep ID: {sweep_id}\")\n",
        "        print(\"Starting Agent... (This will run multiple experiments)\")\n",
        "\n",
        "        # CORRECTION: We use the explicit REPO_ROOT variable defined at the top\n",
        "        !cd {REPO_ROOT} && wandb agent {sweep_id} --count 20\n",
        "    else:\n",
        "        print(\"\\nERROR: Could not find Sweep ID.\")"
      ],
      "metadata": {
        "id": "OE8v94eqa7zn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "0034c387-2513-46f8-ce33-59c101e3e97e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering Sweep from /content/WildfireDetectionDL/conf/sweep.yaml\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-881789450.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 3. Register the sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     result = subprocess.run(\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"wandb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sweep\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSWEEP_CONFIG_PATH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m                 \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                             'failed to raise TimeoutExpired.')\n\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the sweep execution we found the best configuration for the neural networks, now we train the resnet50 using that parameters, we train using both synthetic+real, and only real"
      ],
      "metadata": {
        "id": "qLOavfqgtSmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "# ResNet50\n",
        "RESNET_CONFIG = [\n",
        "    \"model.name=resnet50\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=11\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00005836874490583941\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000621085260935666\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "# SimpleCNN\n",
        "SIMPLE_CNN_CONFIG = [\n",
        "    \"model.name=simple_cnn\",\n",
        "    \"model.dropout=0.5\",\n",
        "    \"dataset.augmentation.rotation_degrees=4\",\n",
        "    \"training.batch_size=64\",\n",
        "    \"training.learning_rate=0.00001349\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.00000823\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "# EfficientNet\n",
        "EFFICIENTNET_CONFIG = [\n",
        "    \"model.name=efficientnet\",\n",
        "    \"model.dropout=0.2\",\n",
        "    \"dataset.augmentation.rotation_degrees=15\",\n",
        "    \"training.batch_size=32\",\n",
        "    \"training.learning_rate=0.0001\",\n",
        "    \"training.optimizer=adam\",\n",
        "    \"training.weight_decay=0.0\",\n",
        "    \"training.epochs=20\",\n",
        "    \"dataset.params.real_data_fraction=0.1\"\n",
        "]\n",
        "\n",
        "\n",
        "def run_training_pipeline(model_label, use_synthetic, specific_config):\n",
        "    # Create a clear name for WandB\n",
        "    run_name = f\"{model_label}_10pct_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "\n",
        "    print(f\"STARTING: {run_name}\")\n",
        "\n",
        "    # Build the command\n",
        "    cmd = [\n",
        "        sys.executable, \"train.py\",\n",
        "        \"wandb.project=wildfire-final-benchmark\",\n",
        "        f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "        f\"+wandb.name={run_name}\",      # Pass the name to Hydra/WandB\n",
        "        f\"+wandb.group={model_label}\"   # Group by model architecture\n",
        "    ] + specific_config\n",
        "\n",
        "    try:\n",
        "        # Use Popen to stream output\n",
        "        process = subprocess.Popen(\n",
        "            cmd,\n",
        "            cwd=\"/content/WildfireDetectionDL\",\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.STDOUT,\n",
        "            text=True,\n",
        "            bufsize=1,\n",
        "            universal_newlines=True\n",
        "        )\n",
        "\n",
        "        # Stream output to console\n",
        "        for line in process.stdout:\n",
        "            print(line, end=\"\")\n",
        "\n",
        "        process.wait()\n",
        "\n",
        "        if process.returncode != 0:\n",
        "            print(f\"\\nFAILED: {run_name}\")\n",
        "        else:\n",
        "            print(f\"\\nCOMPLETE: {run_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"CRITICAL ERROR: {e}\")\n",
        "\n",
        "\n",
        "#ResNet50\n",
        "run_training_pipeline(\"ResNet50\", False, RESNET_CONFIG) # Baseline (10% Real)\n",
        "run_training_pipeline(\"ResNet50\", True, RESNET_CONFIG)  # Experiment (10% Real + Synthetic)\n",
        "\n",
        "#SimpleCNN\n",
        "run_training_pipeline(\"SimpleCNN\", False, SIMPLE_CNN_CONFIG)\n",
        "run_training_pipeline(\"SimpleCNN\", True, SIMPLE_CNN_CONFIG)\n",
        "\n",
        "#EfficientNet\n",
        "run_training_pipeline(\"EfficientNet\", False, EFFICIENTNET_CONFIG)\n",
        "run_training_pipeline(\"EfficientNet\", True, EFFICIENTNET_CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_3baXIXtQ20",
        "outputId": "cb817f58-e256-45f8-c004-c061df159bf5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTING: ResNet50_10pct_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run mp9dykcg\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_090235-mp9dykcg\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run ResNet50_10pct_RealOnly\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/mp9dykcg\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: resnet50\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 48\n",
            "DEBUG: Initializing Model...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "\n",
            "  0%|          | 0.00/97.8M [00:00<?, ?B/s]\n",
            " 18%|‚ñà‚ñä        | 17.2M/97.8M [00:00<00:00, 180MB/s]\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 41.0M/97.8M [00:00<00:00, 221MB/s]\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 64.5M/97.8M [00:00<00:00, 232MB/s]\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 88.2M/97.8M [00:00<00:00, 238MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 232MB/s]\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 15/48 [00:10<00:22,  1.49it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:20<00:00,  2.42it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:20<00:00,  2.29it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.60%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 32/48 [00:10<00:05,  3.13it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:14<00:00,  3.21it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 95.95%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 3:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 32/48 [00:10<00:05,  3.10it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.19it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 96.97%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 4:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.08it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.17it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.49%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 5:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.05it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.67%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 6:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.04it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.12it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.73%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 7:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.83%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 8:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.07it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.70%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 9:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.05it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.79%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 10:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.05%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 11:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.86%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 12:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.11%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 13:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.17%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 14:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.05it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.81%\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 15:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.17%\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 16:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.57%\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 17:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.75%\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 18:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 31/48 [00:10<00:05,  3.06it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:15<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading wandb-summary.json; uploading config.yaml\n",
            "wandb: uploading history steps 17-17, summary, console lines 112-114\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 18\n",
            "wandb: val_acc 97.98413\n",
            "wandb: \n",
            "wandb: üöÄ View run ResNet50_10pct_RealOnly at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/mp9dykcg\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_090235-mp9dykcg/logs\n",
            "   Val Acc: 97.98%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: ResNet50_10pct_RealOnly\n",
            "STARTING: ResNet50_10pct_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run e3jg24rr\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_091153-e3jg24rr\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run ResNet50_10pct_Synthetic\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/e3jg24rr\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: resnet50\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 5024 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 79\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 1:  25%|‚ñà‚ñà‚ñå       | 20/79 [00:10<00:29,  1.97it/s]\n",
            "Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 52/79 [00:20<00:10,  2.68it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:30<00:00,  2.61it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 94.67%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 2:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 2:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 96.83%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 3:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.06it/s]\n",
            "Epoch 3:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.14it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.16it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 96.87%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 4:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.04it/s]\n",
            "Epoch 4:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.12it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.14it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.71%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 5:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 5:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.79%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 6:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 6:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.78%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 7:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 7:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.76%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 8:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 8:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.62%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 9:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 9:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.35%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 10:  39%|‚ñà‚ñà‚ñà‚ñâ      | 31/79 [00:10<00:15,  3.05it/s]\n",
            "Epoch 10:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 63/79 [00:20<00:05,  3.13it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:25<00:00,  3.15it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading wandb-summary.json; uploading output.log\n",
            "wandb: uploading wandb-summary.json; uploading config.yaml\n",
            "wandb: uploading history steps 9-9, summary, console lines 67-69\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 10\n",
            "wandb: val_acc 97.14286\n",
            "wandb: \n",
            "wandb: üöÄ View run ResNet50_10pct_Synthetic at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/e3jg24rr\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_091153-e3jg24rr/logs\n",
            "   Val Acc: 97.14%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: ResNet50_10pct_Synthetic\n",
            "STARTING: SimpleCNN_10pct_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run wsl9bp4f\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_091845-wsl9bp4f\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run SimpleCNN_10pct_RealOnly\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/wsl9bp4f\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: simple_cnn\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 48\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:08<00:00,  5.55it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 90.29%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.50it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.14%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.42it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 90.56%\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.58it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.48%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.54it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.59%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.34it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.62%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.56it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.98%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.33it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.37%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.54it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.84%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.56it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.56%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.45it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.76%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.29%\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.45it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.30%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.48it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.90%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.38it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.10%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.42it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.25%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.40it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.29%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.34it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.43%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 19/20\n",
            "\n",
            "Epoch 19:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.44it/s]\n",
            "DEBUG: Epoch 19 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.46%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 20/20\n",
            "\n",
            "Epoch 20:   0%|          | 0/48 [00:00<?, ?it/s]\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:07<00:00,  6.51it/s]\n",
            "DEBUG: Epoch 20 Training Done. Processed 48 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: uploading artifact model-simple_cnn-wsl9bp4f; updating run metadata\n",
            "wandb: uploading artifact model-simple_cnn-wsl9bp4f; uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading artifact model-simple_cnn-wsl9bp4f\n",
            "wandb: uploading data\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 20\n",
            "wandb: val_acc 93.52381\n",
            "wandb: \n",
            "wandb: üöÄ View run SimpleCNN_10pct_RealOnly at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/wsl9bp4f\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 32 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_091845-wsl9bp4f/logs\n",
            "   Val Acc: 93.52%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: SimpleCNN_10pct_RealOnly\n",
            "STARTING: SimpleCNN_10pct_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run 994zob9z\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_092648-994zob9z\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run SimpleCNN_10pct_Synthetic\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/994zob9z\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: simple_cnn\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 5024 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 79\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 53/79 [00:10<00:05,  5.19it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:14<00:00,  5.31it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 90.59%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.78it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.91it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 90.89%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 3:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.73it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.82it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.65%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 4:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:10<00:03,  5.69it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.79it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 90.44%\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 5:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.76it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.82it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.08%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 6:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.78it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.91it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.60%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 7:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:10<00:03,  5.65it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.69it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.44%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 8:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.78it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.84it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.21%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 9:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.81it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.90it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.68%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 10:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.77it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.87it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.56%\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 11:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.80it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.88it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.41%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 12:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.80it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.92it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.37%\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 13:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.79it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.90it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.44%\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 14:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.79it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.90it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.70%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 15:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:10<00:03,  5.66it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.72it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.70%\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 16:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.80it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.92it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.92%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 17:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 57/79 [00:10<00:03,  5.60it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.76it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 91.57%\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 18:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.78it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.85it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 93.11%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 19/20\n",
            "\n",
            "Epoch 19:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 19:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 58/79 [00:10<00:03,  5.76it/s]\n",
            "Epoch 19: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.80it/s]\n",
            "DEBUG: Epoch 19 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 92.97%\n",
            "DEBUG: Start Epoch 20/20\n",
            "\n",
            "Epoch 20:   0%|          | 0/79 [00:00<?, ?it/s]\n",
            "Epoch 20:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 59/79 [00:10<00:03,  5.80it/s]\n",
            "Epoch 20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:13<00:00,  5.85it/s]\n",
            "DEBUG: Epoch 20 Training Done. Processed 79 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: uploading artifact model-simple_cnn-994zob9z; updating run metadata\n",
            "wandb: uploading artifact model-simple_cnn-994zob9z; uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading artifact model-simple_cnn-994zob9z; uploading output.log; uploading config.yaml; uploading history steps 19-19, summary, console lines 121-123\n",
            "wandb: uploading artifact model-simple_cnn-994zob9z\n",
            "wandb: uploading data\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñà‚ñá‚ñà\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 20\n",
            "wandb: val_acc 93.22222\n",
            "wandb: \n",
            "wandb: üöÄ View run SimpleCNN_10pct_Synthetic at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/994zob9z\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 20 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_092648-994zob9z/logs\n",
            "   Val Acc: 93.22%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: SimpleCNN_10pct_Synthetic\n",
            "STARTING: EfficientNet_10pct_RealOnly\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run rotzgv38\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_093639-rotzgv38\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run EfficientNet_10pct_RealOnly\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/rotzgv38\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: efficientnet\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "   Baseline Mode: Real Data Only\n",
            "DEBUG: Data Loaded. Train batches: 95\n",
            "DEBUG: Initializing Model...\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "\n",
            "  0%|          | 0.00/20.5M [00:00<?, ?B/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 234MB/s]\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 1:   1%|          | 1/95 [00:14<21:58, 14.02s/it]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:35<00:00,  3.07it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:35<00:00,  2.71it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 96.60%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.07it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.49%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.07it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.78%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.12it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.03%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.15it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.05%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.11it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.14%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.09it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.33%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.12it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.29%\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.13it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.21%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.13it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.17%\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.13it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.10%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/95 [00:00<?, ?it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95/95 [00:08<00:00, 11.14it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 95 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 11-11, summary, console lines 79-81\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 12\n",
            "wandb: val_acc 98.33333\n",
            "wandb: \n",
            "wandb: üöÄ View run EfficientNet_10pct_RealOnly at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/rotzgv38\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_093639-rotzgv38/logs\n",
            "   Val Acc: 98.33%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: EfficientNet_10pct_RealOnly\n",
            "STARTING: EfficientNet_10pct_Synthetic\n",
            "wandb: Currently logged in as: pozioniccolo (pozioniccolo-sapienza-universit-di-roma) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: setting up run 8zc5d5k7\n",
            "wandb: Tracking run with wandb version 0.23.0\n",
            "wandb: Run data is saved locally in /content/WildfireDetectionDL/wandb/run-20251205_094205-8zc5d5k7\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run EfficientNet_10pct_Synthetic\n",
            "wandb: ‚≠êÔ∏è View project at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: üöÄ View run at https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/8zc5d5k7\n",
            "DEBUG: Starting main function...\n",
            "DEBUG: Initializing WandB...\n",
            "DEBUG: WandB Initialized.\n",
            "Training on cuda using model: efficientnet\n",
            "DEBUG: Loading Data...\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "SCARCITY MODE: Using 10.0% of Real Data.\n",
            "   Real Training Samples: 3024\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 5024 (Real + Synthetic)\n",
            "DEBUG: Data Loaded. Train batches: 157\n",
            "DEBUG: Initializing Model...\n",
            "Starting Training Loop...\n",
            "DEBUG: Start Epoch 1/20\n",
            "\n",
            "Epoch 1:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 1:   1%|          | 1/157 [00:13<35:34, 13.68s/it]\n",
            "Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 116/157 [00:23<00:06,  5.89it/s]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:27<00:00,  5.73it/s]\n",
            "DEBUG: Epoch 1 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 96.84%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 2/20\n",
            "\n",
            "Epoch 2:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 111/157 [00:10<00:04, 11.09it/s]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.15it/s]\n",
            "DEBUG: Epoch 2 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.43%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 3/20\n",
            "\n",
            "Epoch 3:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 3:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.12it/s]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.19it/s]\n",
            "DEBUG: Epoch 3 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.16%\n",
            "DEBUG: Start Epoch 4/20\n",
            "\n",
            "Epoch 4:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 4:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.18it/s]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:13<00:00, 11.23it/s]\n",
            "DEBUG: Epoch 4 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.73%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 5/20\n",
            "\n",
            "Epoch 5:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 5:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.14it/s]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.19it/s]\n",
            "DEBUG: Epoch 5 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.06%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 6/20\n",
            "\n",
            "Epoch 6:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 6:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.15it/s]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.20it/s]\n",
            "DEBUG: Epoch 6 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.94%\n",
            "DEBUG: Start Epoch 7/20\n",
            "\n",
            "Epoch 7:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 7:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 111/157 [00:10<00:04, 11.05it/s]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.09it/s]\n",
            "DEBUG: Epoch 7 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.94%\n",
            "DEBUG: Start Epoch 8/20\n",
            "\n",
            "Epoch 8:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 8:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.12it/s]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.17it/s]\n",
            "DEBUG: Epoch 8 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.22%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 9/20\n",
            "\n",
            "Epoch 9:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 9:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 106/157 [00:10<00:04, 10.58it/s]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.81it/s]\n",
            "DEBUG: Epoch 9 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.11%\n",
            "DEBUG: Start Epoch 10/20\n",
            "\n",
            "Epoch 10:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 10:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 106/157 [00:10<00:04, 10.52it/s]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.76it/s]\n",
            "DEBUG: Epoch 10 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.24%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 11/20\n",
            "\n",
            "Epoch 11:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 11:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/157 [00:10<00:04, 10.87it/s]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.99it/s]\n",
            "DEBUG: Epoch 11 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.10%\n",
            "DEBUG: Start Epoch 12/20\n",
            "\n",
            "Epoch 12:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 12:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/157 [00:10<00:04, 10.82it/s]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.96it/s]\n",
            "DEBUG: Epoch 12 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.95%\n",
            "DEBUG: Start Epoch 13/20\n",
            "\n",
            "Epoch 13:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 13:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/157 [00:10<00:04, 10.88it/s]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.02it/s]\n",
            "DEBUG: Epoch 13 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.27%\n",
            "   New Best! Saving Artifact...\n",
            "DEBUG: Start Epoch 14/20\n",
            "\n",
            "Epoch 14:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 14:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 110/157 [00:10<00:04, 10.91it/s]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.02it/s]\n",
            "DEBUG: Epoch 14 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.87%\n",
            "DEBUG: Start Epoch 15/20\n",
            "\n",
            "Epoch 15:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 15:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 109/157 [00:10<00:04, 10.81it/s]\n",
            "Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.96it/s]\n",
            "DEBUG: Epoch 15 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.21%\n",
            "DEBUG: Start Epoch 16/20\n",
            "\n",
            "Epoch 16:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 16:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 107/157 [00:10<00:04, 10.66it/s]\n",
            "Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 10.86it/s]\n",
            "DEBUG: Epoch 16 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 98.25%\n",
            "DEBUG: Start Epoch 17/20\n",
            "\n",
            "Epoch 17:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 17:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 110/157 [00:10<00:04, 10.93it/s]\n",
            "Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.05it/s]\n",
            "DEBUG: Epoch 17 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "   Val Acc: 97.94%\n",
            "DEBUG: Start Epoch 18/20\n",
            "\n",
            "Epoch 18:   0%|          | 0/157 [00:00<?, ?it/s]\n",
            "Epoch 18:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 112/157 [00:10<00:04, 11.13it/s]\n",
            "Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 157/157 [00:14<00:00, 11.18it/s]\n",
            "DEBUG: Epoch 18 Training Done. Processed 157 batches.\n",
            "DEBUG: Starting Validation...\n",
            "wandb: updating run metadata\n",
            "wandb: uploading output.log; uploading wandb-summary.json\n",
            "wandb: uploading output.log; uploading config.yaml\n",
            "wandb: uploading history steps 17-17, summary, console lines 109-111\n",
            "wandb: \n",
            "wandb: Run history:\n",
            "wandb:   epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà\n",
            "wandb: val_acc ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñÜ‚ñà‚ñà‚ñÜ‚ñà\n",
            "wandb: \n",
            "wandb: Run summary:\n",
            "wandb:   epoch 18\n",
            "wandb: val_acc 98.19048\n",
            "wandb: \n",
            "wandb: üöÄ View run EfficientNet_10pct_Synthetic at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark/runs/8zc5d5k7\n",
            "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pozioniccolo-sapienza-universit-di-roma/wildfire-final-benchmark\n",
            "wandb: Synced 5 W&B file(s), 0 media file(s), 14 artifact file(s) and 0 other file(s)\n",
            "wandb: Find logs at: ./wandb/run-20251205_094205-8zc5d5k7/logs\n",
            "   Val Acc: 98.19%\n",
            "   Early Stopping.\n",
            "DEBUG: Finishing Run...\n",
            "\n",
            "COMPLETE: EfficientNet_10pct_Synthetic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Basic settings for the project\n",
        "# Make sure you are logged in with wandb.login() before running this\n",
        "PROJECT = \"wildfire-final-benchmark\"\n",
        "ENTITY = wandb.Api().default_entity\n",
        "\n",
        "# This is where the repository is cloned in Colab\n",
        "REPO_DIR = \"/content/WildfireDetectionDL\"\n",
        "\n",
        "# These are the exact configurations we want to benchmark\n",
        "TARGETS = [\n",
        "    (\"ResNet50\", False), (\"ResNet50\", True),\n",
        "    (\"SimpleCNN\", False), (\"SimpleCNN\", True),\n",
        "    (\"EfficientNet\", False), (\"EfficientNet\", True),\n",
        "]\n",
        "\n",
        "def parse_metrics(output_text):\n",
        "    # We use regex here to pull the numbers out of the console output\n",
        "    # This expects the test.py script to print lines like \"Accuracy: 0.95\"\n",
        "    metrics = {}\n",
        "    patterns = {\n",
        "        \"Accuracy\": r\"Accuracy:\\s+([0-9.]+)\",\n",
        "        \"Precision\": r\"Precision:\\s+([0-9.]+)\",\n",
        "        \"Recall\": r\"Recall:\\s+([0-9.]+)\",\n",
        "        \"F1-Score\": r\"F1-Score:\\s+([0-9.]+)\"\n",
        "    }\n",
        "\n",
        "    for key, pattern in patterns.items():\n",
        "        match = re.search(pattern, output_text)\n",
        "        if match:\n",
        "            metrics[key] = float(match.group(1))\n",
        "        else:\n",
        "            # If we can't find the metric, default to 0 so the script doesn't crash\n",
        "            metrics[key] = 0.0\n",
        "    return metrics\n",
        "\n",
        "def run_colab_testing_pipeline():\n",
        "    api = wandb.Api()\n",
        "    results_data = []\n",
        "\n",
        "    print(f\"Starting Benchmark Evaluation on Project: {PROJECT}\\n\")\n",
        "\n",
        "    for model_label, use_synthetic in TARGETS:\n",
        "        # Recreate the run name so we can find it in the cloud.\n",
        "        # This matches the +wandb.name argument we used during training.\n",
        "        run_name = f\"{model_label}_10pct_{'Synthetic' if use_synthetic else 'RealOnly'}\"\n",
        "        print(f\"PROCESSING: {run_name}\")\n",
        "\n",
        "        # Search for the run in WandB history\n",
        "        runs = api.runs(f\"{ENTITY}/{PROJECT}\", filters={\"display_name\": run_name, \"state\": \"finished\"}, order=\"-created_at\")\n",
        "        if len(runs) == 0:\n",
        "            print(f\"[ERROR] Could not find a finished run named '{run_name}'. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # If there are duplicates, the first one is usually the most recent\n",
        "        target_run = runs[0]\n",
        "        print(f\" >> Found Run ID: {target_run.id}\")\n",
        "\n",
        "        # Check if this run actually has a model saved\n",
        "        try:\n",
        "            logged_artifacts = target_run.logged_artifacts()\n",
        "            model_artifacts = [a for a in logged_artifacts if a.type == 'model']\n",
        "\n",
        "            if not model_artifacts:\n",
        "                print(f\" >> [ERROR] Run exists but has no model artifact. Skipping.\")\n",
        "                continue\n",
        "\n",
        "            artifact = model_artifacts[0]\n",
        "            print(f\" >> Downloading Artifact: {artifact.name}\")\n",
        "\n",
        "            # Download the weights to the local Colab disk\n",
        "            download_dir = artifact.download()\n",
        "\n",
        "            # We need the absolute path because the subprocess runs in a different folder\n",
        "            weight_path = os.path.abspath(os.path.join(download_dir, \"model_weights.pth\"))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" >> [ERROR] Problem downloading artifact: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Now we figure out the architecture details from the config\n",
        "        # This is important so we don't accidentally load a ResNet into a SimpleCNN\n",
        "        train_config = target_run.config\n",
        "        try:\n",
        "            # Sometimes config is nested (model -> dropout), sometimes flat (model.dropout)\n",
        "            # We try both ways to be safe\n",
        "            if 'model' in train_config and isinstance(train_config['model'], dict):\n",
        "                model_dropout = train_config['model'].get('dropout', 0.0)\n",
        "                model_arch_name = train_config['model'].get('name')\n",
        "            else:\n",
        "                model_dropout = train_config.get('model.dropout', 0.0)\n",
        "                model_arch_name = train_config.get('model.name')\n",
        "\n",
        "            # If the config is missing the name, assume it matches our loop label\n",
        "            if not model_arch_name:\n",
        "                model_arch_name = model_label.lower()\n",
        "\n",
        "        except Exception:\n",
        "            # If everything fails, use safe defaults\n",
        "            print(\" >> [WARNING] Could not read config. Using defaults.\")\n",
        "            model_dropout = 0.5\n",
        "            model_arch_name = model_label.lower()\n",
        "\n",
        "        print(f\" >> Configuration inferred: Arch={model_arch_name}, Dropout={model_dropout}\")\n",
        "\n",
        "        # Prepare the command to run test.py\n",
        "        cmd = [\n",
        "            sys.executable, \"test.py\",\n",
        "            f\"model.name={model_arch_name}\",\n",
        "            f\"model.dropout={model_dropout}\",\n",
        "            f\"dataset.params.use_synthetic={str(use_synthetic).lower()}\",\n",
        "            \"wandb.mode=disabled\",\n",
        "            f\"+model_path={weight_path}\"\n",
        "        ]\n",
        "\n",
        "        print(\" >> Starting test execution...\")\n",
        "\n",
        "        # Using Popen allows us to see the output line by line as it happens\n",
        "        try:\n",
        "            process = subprocess.Popen(\n",
        "                cmd,\n",
        "                cwd=REPO_DIR,    # Run inside the repo folder so imports work\n",
        "                stdout=subprocess.PIPE,\n",
        "                stderr=subprocess.STDOUT, # Merge errors into main output\n",
        "                text=True,\n",
        "                bufsize=1,\n",
        "                universal_newlines=True\n",
        "            )\n",
        "\n",
        "            # We need to capture the full output to parse metrics later,\n",
        "            # but we also want to print it now so the user sees progress.\n",
        "            full_console_output = \"\"\n",
        "\n",
        "            for line in process.stdout:\n",
        "                print(line, end=\"\")\n",
        "                full_console_output += line\n",
        "\n",
        "            process.wait()\n",
        "\n",
        "            if process.returncode == 0:\n",
        "                print(\"\\n >> [SUCCESS] Test finished.\")\n",
        "\n",
        "                # Extract the numbers from the text we just captured\n",
        "                metrics = parse_metrics(full_console_output)\n",
        "\n",
        "                entry = {\n",
        "                    \"Model\": model_label,\n",
        "                    \"Data\": \"Synthetic\" if use_synthetic else \"RealOnly\",\n",
        "                    \"Run_ID\": target_run.id,\n",
        "                    **metrics\n",
        "                }\n",
        "                results_data.append(entry)\n",
        "            else:\n",
        "                print(\"\\n >> [FAILURE] The test script crashed.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\" >> [ERROR] subprocess failed: {e}\")\n",
        "\n",
        "    # Finally, save everything to a CSV file\n",
        "    if results_data:\n",
        "        df = pd.DataFrame(results_data)\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"FINAL BENCHMARK RESULTS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(df)\n",
        "        df.to_csv(\"benchmark_results.csv\", index=False)\n",
        "        print(\"\\nResults saved to benchmark_results.csv\")\n",
        "    else:\n",
        "        print(\"\\nNo results gathered.\")\n",
        "\n",
        "# Run the function\n",
        "if __name__ == \"__main__\":\n",
        "    run_colab_testing_pipeline()"
      ],
      "metadata": {
        "id": "XzT7nl5MA7cO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1961fa9-29df-4781-b7da-0e47ce2bba94"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Benchmark Evaluation on Project: wildfire-final-benchmark\n",
            "\n",
            "PROCESSING: ResNet50_10pct_RealOnly\n",
            " >> Found Run ID: mp9dykcg\n",
            " >> Downloading Artifact: model-resnet50-mp9dykcg:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-resnet50-mp9dykcg:v0', 90.00MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.6 (152.6MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=resnet50, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: resnet50\n",
            "DEBUG: Processing 320 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9490\n",
            "Precision: 0.9713\n",
            "Recall:    0.9353\n",
            "F1-Score:  0.9530\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "PROCESSING: ResNet50_10pct_Synthetic\n",
            " >> Found Run ID: e3jg24rr\n",
            " >> Downloading Artifact: model-resnet50-e3jg24rr:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-resnet50-e3jg24rr:v0', 90.00MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.4 (239.8MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=resnet50, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: resnet50\n",
            "DEBUG: Processing 320 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9600\n",
            "Precision: 0.9521\n",
            "Recall:    0.9767\n",
            "F1-Score:  0.9642\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "PROCESSING: SimpleCNN_10pct_RealOnly\n",
            " >> Found Run ID: wsl9bp4f\n",
            " >> Downloading Artifact: model-simple_cnn-wsl9bp4f:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-simple_cnn-wsl9bp4f:v0', 196.37MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.4 (479.5MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=simple_cnn, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: simple_cnn\n",
            "DEBUG: Processing 10 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9086\n",
            "Precision: 0.9270\n",
            "Recall:    0.9057\n",
            "F1-Score:  0.9163\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "PROCESSING: SimpleCNN_10pct_Synthetic\n",
            " >> Found Run ID: 994zob9z\n",
            " >> Downloading Artifact: model-simple_cnn-994zob9z:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact 'model-simple_cnn-994zob9z:v0', 196.37MB. 1 files...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 00:00:00.4 (490.6MB/s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=simple_cnn, Dropout=0.5\n",
            " >> Starting test execution...\n",
            "Testing Model: simple_cnn\n",
            "DEBUG: Processing 10 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9127\n",
            "Precision: 0.8867\n",
            "Recall:    0.9652\n",
            "F1-Score:  0.9243\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "PROCESSING: EfficientNet_10pct_RealOnly\n",
            " >> Found Run ID: rotzgv38\n",
            " >> Downloading Artifact: model-efficientnet-rotzgv38:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=efficientnet, Dropout=0.2\n",
            " >> Starting test execution...\n",
            "Testing Model: efficientnet\n",
            "DEBUG: Processing 360 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "   Baseline Mode: Real Data Only\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9727\n",
            "Precision: 0.9750\n",
            "Recall:    0.9756\n",
            "F1-Score:  0.9753\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "PROCESSING: EfficientNet_10pct_Synthetic\n",
            " >> Found Run ID: 8zc5d5k7\n",
            " >> Downloading Artifact: model-efficientnet-8zc5d5k7:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " >> Configuration inferred: Arch=efficientnet, Dropout=0.2\n",
            " >> Starting test execution...\n",
            "Testing Model: efficientnet\n",
            "DEBUG: Processing 360 keys from artifact...\n",
            ">> SUCCESS: Weights loaded with strict=True\n",
            "Class Mapping Locked: {'nowildfire': 0, 'wildfire': 1}\n",
            "   -> Synthetic data will use Class Index: 1\n",
            "   Real Training Samples: 30249\n",
            "SYNTHETIC INJECTION: Enabled\n",
            "   -> Found 2000 synthetic wildfire images (Label: 1).\n",
            "Total Training Size: 32249 (Real + Synthetic)\n",
            "\n",
            "RESULTS:\n",
            "Accuracy:  0.9748\n",
            "Precision: 0.9681\n",
            "Recall:    0.9868\n",
            "F1-Score:  0.9774\n",
            "\n",
            " >> [SUCCESS] Test finished.\n",
            "\n",
            "============================================================\n",
            "FINAL BENCHMARK RESULTS\n",
            "============================================================\n",
            "          Model       Data    Run_ID  Accuracy  Precision  Recall  F1-Score\n",
            "0      ResNet50   RealOnly  mp9dykcg    0.9490     0.9713  0.9353    0.9530\n",
            "1      ResNet50  Synthetic  e3jg24rr    0.9600     0.9521  0.9767    0.9642\n",
            "2     SimpleCNN   RealOnly  wsl9bp4f    0.9086     0.9270  0.9057    0.9163\n",
            "3     SimpleCNN  Synthetic  994zob9z    0.9127     0.8867  0.9652    0.9243\n",
            "4  EfficientNet   RealOnly  rotzgv38    0.9727     0.9750  0.9756    0.9753\n",
            "5  EfficientNet  Synthetic  8zc5d5k7    0.9748     0.9681  0.9868    0.9774\n",
            "\n",
            "Results saved to benchmark_results.csv\n"
          ]
        }
      ]
    }
  ]
}